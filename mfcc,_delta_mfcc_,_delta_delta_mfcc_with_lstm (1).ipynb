{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEcNRfGNQlp8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "\n",
        "import soundfile as sf\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy.io import wavfile\n",
        "import scipy.signal\n",
        "from PIL import Image\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49Rpm_HgQxyk"
      },
      "outputs": [],
      "source": [
        "#import noisereduce as nr\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.signal import lfilter, butter\n",
        "#import keras_tuner as kt\n",
        "#from kerastuner import HyperModel\n",
        "#from keras_tuner import RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-0OwjsUQ0HJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "#from hmmlearn import hmm\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import  VotingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.datasets import make_classification\n",
        "from scipy.stats import uniform, randint\n",
        "from keras import optimizers\n",
        "from keras import losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PTCYoiFQ579"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXloQhITQ6Ye"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM,GRU\n",
        "from keras import regularizers\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from keras.optimizers import Adam, SGD, RMSprop, Adadelta\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.layers import  Bidirectional,RepeatVector, TimeDistributed\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "from keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYJrJvnrQ9b7",
        "outputId": "4e514bf8-1c87-48b0-d8b0-6e7d0d072349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading ravdess-emotional-speech-audio.zip to /content\n",
            " 98% 422M/429M [00:04<00:00, 91.3MB/s]\n",
            "100% 429M/429M [00:05<00:00, 89.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RCQ_Z3dRAEs"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/ravdess-emotional-speech-audio.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhCzmC9wREgi"
      },
      "outputs": [],
      "source": [
        "paths = []\n",
        "labels = []\n",
        "for dirname, _, filenames in os.walk('/content/audio_speech_actors_01-24'):\n",
        "    for filename in filenames:\n",
        "        paths.append(os.path.join(dirname, filename))\n",
        "        parts = filename.split('-')\n",
        "\n",
        "        if len(parts) >= 3:\n",
        "            label = parts[2]  # Get the 3rd term\n",
        "            labels.append(label)\n",
        "        else:\n",
        "            print(f\"Skipping file with unexpected format: {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "J1JbTaPeRIRO",
        "outputId": "0da058c4-5300-4b1c-e532-87e932a8899a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1440,\n  \"fields\": [\n    {\n      \"column\": \"speech\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1440,\n        \"samples\": [\n          \"/content/audio_speech_actors_01-24/Actor_07/03-01-05-01-01-02-07.wav\",\n          \"/content/audio_speech_actors_01-24/Actor_08/03-01-07-01-01-01-08.wav\",\n          \"/content/audio_speech_actors_01-24/Actor_01/03-01-06-01-02-01-01.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"08\",\n          \"06\",\n          \"07\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3bb2887b-144e-40cb-bdd9-0b011556fb12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/audio_speech_actors_01-24/Actor_19/03...</td>\n",
              "      <td>07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/audio_speech_actors_01-24/Actor_19/03...</td>\n",
              "      <td>08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/audio_speech_actors_01-24/Actor_19/03...</td>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/audio_speech_actors_01-24/Actor_19/03...</td>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/audio_speech_actors_01-24/Actor_19/03...</td>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bb2887b-144e-40cb-bdd9-0b011556fb12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3bb2887b-144e-40cb-bdd9-0b011556fb12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3bb2887b-144e-40cb-bdd9-0b011556fb12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2ab8b4f5-d7cc-486f-bdb3-6cd2bab8a12f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ab8b4f5-d7cc-486f-bdb3-6cd2bab8a12f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2ab8b4f5-d7cc-486f-bdb3-6cd2bab8a12f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              speech label\n",
              "0  /content/audio_speech_actors_01-24/Actor_19/03...    07\n",
              "1  /content/audio_speech_actors_01-24/Actor_19/03...    08\n",
              "2  /content/audio_speech_actors_01-24/Actor_19/03...    04\n",
              "3  /content/audio_speech_actors_01-24/Actor_19/03...    04\n",
              "4  /content/audio_speech_actors_01-24/Actor_19/03...    04"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Create a RAVDESS dataframe\n",
        "df= pd.DataFrame()\n",
        "df['speech'] = paths\n",
        "df['label'] = labels\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaYtdG-SRNFY"
      },
      "outputs": [],
      "source": [
        "# Define preprocessing parameters\n",
        "TARGET_SAMPLE_RATE = 48000   # Desired sample rate for resampling\n",
        "FRAME_SIZE = 1200            # Frame size in samples (25 ms)\n",
        "HOP_LENGTH = 600             # Hop length in samples (50% overlap)\n",
        "MFCC_N_MFCC = 13             # Number of MFCC coefficients to extract\n",
        "PAD_LENGTH = 5 * TARGET_SAMPLE_RATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvvl5p_VTNTl"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess audio\n",
        "def preprocess_audio(file_path, target_sr=TARGET_SAMPLE_RATE, pad_length=PAD_LENGTH):\n",
        "    # Load the audio\n",
        "    y, sr = librosa.load(file_path, sr=target_sr)\n",
        "\n",
        "    # Step 1: Silence Removal (Using librosa.effects.trim)\n",
        "    y, _ = librosa.effects.trim(y)\n",
        "\n",
        "    # Step 2: Padding (if the audio is shorter than the target length)\n",
        "    if len(y) < pad_length:\n",
        "        padding = pad_length - len(y)\n",
        "        y = np.pad(y, (0, padding), 'constant')  # Zero padding at the end\n",
        "\n",
        "    # Step 3: Normalization (Peak normalization to [-1, 1] range)\n",
        "    y = librosa.util.normalize(y)\n",
        "\n",
        "    return y, target_sr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04CL1duTbDnw"
      },
      "outputs": [],
      "source": [
        "# Function to extract raw MFCC features\n",
        "def extract_mfcc(audio, sr, frame_size=FRAME_SIZE, hop_length=HOP_LENGTH, n_mfcc=MFCC_N_MFCC):\n",
        "    # Extract MFCC features\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length)\n",
        "    return mfcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6-1PX7rbFF3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Function to extract delta and delta-delta MFCC features\n",
        "def extract_delta_mfcc(mfcc):\n",
        "    # Extract delta MFCC (first-order difference)\n",
        "    delta_mfcc = librosa.feature.delta(mfcc)\n",
        "\n",
        "    # Extract delta-delta MFCC (second-order difference)\n",
        "    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
        "\n",
        "    return delta_mfcc, delta2_mfcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEbwWJ3fbFCg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Helper function to pad or truncate features\n",
        "def pad_or_truncate(features, target_length):\n",
        "    # If the number of frames is less than the target, pad with zeros\n",
        "    if features.shape[1] < target_length:\n",
        "        padding = target_length - features.shape[1]\n",
        "        return np.pad(features, ((0, 0), (0, padding)), mode='constant')\n",
        "    # If the number of frames is more than the target, truncate\n",
        "    elif features.shape[1] > target_length:\n",
        "        return features[:, :target_length]\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzCChiv2bFAL"
      },
      "outputs": [],
      "source": [
        "# Initialize list to store processed data\n",
        "processed_data = []\n",
        "target_num_frames = 400  # Set a target number of frames for padding/truncating\n",
        "scaler = StandardScaler()  # Initialize the scaler\n",
        "\n",
        "# Assuming df1 is already defined and contains the audio paths and labels\n",
        "for index, row in df.iterrows():\n",
        "    audio_path = row['speech']\n",
        "    label = row['label']\n",
        "\n",
        "    # Preprocess the audio\n",
        "    y, sr = preprocess_audio(audio_path)\n",
        "\n",
        "    # Extract raw MFCC features (shape: (n_mfcc, num_frames))\n",
        "    raw_mfcc = extract_mfcc(y, sr)\n",
        "\n",
        "    # Extract delta and delta-delta MFCC features\n",
        "    delta_mfcc, delta2_mfcc = extract_delta_mfcc(raw_mfcc)\n",
        "\n",
        "    # Pad or truncate MFCC, delta MFCC, and delta-delta MFCC to ensure consistent number of frames\n",
        "    adjusted_mfcc = pad_or_truncate(raw_mfcc, target_num_frames)\n",
        "    adjusted_delta_mfcc = pad_or_truncate(delta_mfcc, target_num_frames)\n",
        "    adjusted_delta2_mfcc = pad_or_truncate(delta2_mfcc, target_num_frames)\n",
        "\n",
        "    # Transpose the MFCC arrays to fit the (num_frames, num_mfcc) format\n",
        "    adjusted_mfcc = adjusted_mfcc.T\n",
        "    adjusted_delta_mfcc = adjusted_delta_mfcc.T\n",
        "    adjusted_delta2_mfcc = adjusted_delta2_mfcc.T\n",
        "\n",
        "    # Normalize each frame's MFCC, delta MFCC, and delta-delta MFCC (standardize)\n",
        "    scaled_mfcc = scaler.fit_transform(adjusted_mfcc)\n",
        "    scaled_delta_mfcc = scaler.fit_transform(adjusted_delta_mfcc)\n",
        "    scaled_delta2_mfcc = scaler.fit_transform(adjusted_delta2_mfcc)\n",
        "\n",
        "    # Combine MFCC, delta MFCC, and delta-delta MFCC features (num_frames, num_mfcc * 3)\n",
        "    combined_features = np.hstack([scaled_mfcc, scaled_delta_mfcc, scaled_delta2_mfcc])\n",
        "\n",
        "    # Append the combined features and label to processed_data\n",
        "    processed_data.append((combined_features, label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xBC0C6dbE9x",
        "outputId": "bcc21729-a463-43dd-8db5-ee70c9590c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (1152, 400, 39)\n",
            "X_test shape: (288, 400, 39)\n",
            "y_train shape: (1152, 8)\n",
            "y_test shape: (288, 8)\n"
          ]
        }
      ],
      "source": [
        " #Create separate lists for features and labels\n",
        "X = [item[0] for item in processed_data]  # List of feature arrays (MFCCs + delta + delta-delta)\n",
        "y = [item[1] for item in processed_data]  # Corresponding labels\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Apply one-hot encoding to the labels\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Updated parameter\n",
        "y_onehot = encoder.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now X_train and X_test contain the combined MFCC, delta, and delta-delta features,\n",
        "# and y_train and y_test contain one-hot encoded labels\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYXLuM4lTppO",
        "outputId": "34071b35-ff4f-4669-dfe4-2dca4a72144e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: (400, 39)\n",
            "Number of classes: 8\n"
          ]
        }
      ],
      "source": [
        "# Input shape\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])  # (num_frames, num_mfcc)\n",
        "print(\"Input shape:\", input_shape)\n",
        "\n",
        "# Number of classes\n",
        "num_classes = y_train.shape[1]  # Number of unique classes\n",
        "print(\"Number of classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z86ujMr7dT0e"
      },
      "source": [
        "###LSTM with attenstion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l837TKZNUANZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vfn7LwFaT_7q"
      },
      "outputs": [],
      "source": [
        "class Attention(Layer):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1), initializer=\"normal\")\n",
        "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1), initializer=\"zeros\")\n",
        "        super(Attention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
        "        a = tf.keras.backend.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return tf.keras.backend.sum(output, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuVuqqAvT_4D"
      },
      "outputs": [],
      "source": [
        "def build_lstm_attention_model1(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add LSTM layers\n",
        "    model.add(LSTM(512, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Add Attention layer\n",
        "    model.add(Attention())\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimozer=Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimozer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "w_2pZd1ST_1v",
        "outputId": "3a79f808-add1-4dc4-b36d-55e1ee71091e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,130,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">328,192</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m1,130,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m328,192\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention (\u001b[38;5;33mAttention\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,475,224</span> (5.63 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,475,224\u001b[0m (5.63 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,473,688</span> (5.62 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,473,688\u001b[0m (5.62 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model summary\n",
        "model_with_attention = build_lstm_attention_model1(input_shape, num_classes)\n",
        "model_with_attention.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B63X8yotT_y_",
        "outputId": "b142ba07-dc2e-4c56-df98-bedb4e3ca4ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.1371 - loss: 2.7180 - val_accuracy: 0.1632 - val_loss: 2.0701\n",
            "Epoch 2/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.2379 - loss: 2.3525 - val_accuracy: 0.1632 - val_loss: 2.0627\n",
            "Epoch 3/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.2629 - loss: 2.1876 - val_accuracy: 0.1632 - val_loss: 2.0545\n",
            "Epoch 4/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.3210 - loss: 1.9830 - val_accuracy: 0.1632 - val_loss: 2.0505\n",
            "Epoch 5/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - accuracy: 0.3121 - loss: 1.9789 - val_accuracy: 0.1632 - val_loss: 2.0455\n",
            "Epoch 6/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step - accuracy: 0.3749 - loss: 1.8215 - val_accuracy: 0.1632 - val_loss: 2.0443\n",
            "Epoch 7/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.3754 - loss: 1.7378 - val_accuracy: 0.1632 - val_loss: 2.0394\n",
            "Epoch 8/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 0.4587 - loss: 1.5530 - val_accuracy: 0.1840 - val_loss: 2.0222\n",
            "Epoch 9/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.4491 - loss: 1.5164 - val_accuracy: 0.2049 - val_loss: 2.0158\n",
            "Epoch 10/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.5040 - loss: 1.4121 - val_accuracy: 0.2257 - val_loss: 1.9896\n",
            "Epoch 11/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.5297 - loss: 1.3565 - val_accuracy: 0.2639 - val_loss: 1.9735\n",
            "Epoch 12/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.5487 - loss: 1.2867 - val_accuracy: 0.2743 - val_loss: 1.9433\n",
            "Epoch 13/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5328 - loss: 1.2534 - val_accuracy: 0.3056 - val_loss: 1.8880\n",
            "Epoch 14/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.6028 - loss: 1.1464 - val_accuracy: 0.3056 - val_loss: 1.8469\n",
            "Epoch 15/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5973 - loss: 1.1061 - val_accuracy: 0.3368 - val_loss: 1.8124\n",
            "Epoch 16/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.6310 - loss: 1.0734 - val_accuracy: 0.3715 - val_loss: 1.7635\n",
            "Epoch 17/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6268 - loss: 1.0432 - val_accuracy: 0.4514 - val_loss: 1.6391\n",
            "Epoch 18/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6470 - loss: 1.0062 - val_accuracy: 0.4826 - val_loss: 1.5937\n",
            "Epoch 19/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.6959 - loss: 0.9254 - val_accuracy: 0.4757 - val_loss: 1.5637\n",
            "Epoch 20/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.6919 - loss: 0.8825 - val_accuracy: 0.4965 - val_loss: 1.4985\n",
            "Epoch 21/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.7081 - loss: 0.8368 - val_accuracy: 0.5417 - val_loss: 1.3783\n",
            "Epoch 22/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.7069 - loss: 0.8371 - val_accuracy: 0.6076 - val_loss: 1.2463\n",
            "Epoch 23/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.7398 - loss: 0.7929 - val_accuracy: 0.6181 - val_loss: 1.1893\n",
            "Epoch 24/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.7804 - loss: 0.7529 - val_accuracy: 0.6354 - val_loss: 1.1165\n",
            "Epoch 25/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.7462 - loss: 0.7281 - val_accuracy: 0.6910 - val_loss: 1.0274\n",
            "Epoch 26/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.7568 - loss: 0.7259 - val_accuracy: 0.6701 - val_loss: 1.0624\n",
            "Epoch 27/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.7684 - loss: 0.6587 - val_accuracy: 0.7014 - val_loss: 0.9702\n",
            "Epoch 28/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.7926 - loss: 0.6551 - val_accuracy: 0.7361 - val_loss: 0.9260\n",
            "Epoch 29/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.7831 - loss: 0.6380 - val_accuracy: 0.6979 - val_loss: 0.9334\n",
            "Epoch 30/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.7968 - loss: 0.6639 - val_accuracy: 0.7743 - val_loss: 0.7968\n",
            "Epoch 31/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.8194 - loss: 0.5688 - val_accuracy: 0.7604 - val_loss: 0.8008\n",
            "Epoch 32/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.8247 - loss: 0.5548 - val_accuracy: 0.7639 - val_loss: 0.7686\n",
            "Epoch 33/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.8409 - loss: 0.5365 - val_accuracy: 0.7917 - val_loss: 0.7043\n",
            "Epoch 34/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8613 - loss: 0.4924 - val_accuracy: 0.7569 - val_loss: 0.7796\n",
            "Epoch 35/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.8476 - loss: 0.5095 - val_accuracy: 0.7326 - val_loss: 0.7920\n",
            "Epoch 36/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.8561 - loss: 0.4543 - val_accuracy: 0.7604 - val_loss: 0.7457\n",
            "Epoch 37/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8573 - loss: 0.4635 - val_accuracy: 0.7708 - val_loss: 0.7559\n",
            "Epoch 38/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.8820 - loss: 0.4301 - val_accuracy: 0.7604 - val_loss: 0.7380\n",
            "Epoch 39/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.8846 - loss: 0.4007 - val_accuracy: 0.7743 - val_loss: 0.6820\n",
            "Epoch 40/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.8915 - loss: 0.3977 - val_accuracy: 0.7743 - val_loss: 0.7127\n",
            "Epoch 41/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.9001 - loss: 0.3740 - val_accuracy: 0.7951 - val_loss: 0.6904\n",
            "Epoch 42/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.8722 - loss: 0.4240 - val_accuracy: 0.7917 - val_loss: 0.6605\n",
            "Epoch 43/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9011 - loss: 0.3618 - val_accuracy: 0.7882 - val_loss: 0.6720\n",
            "Epoch 44/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.9043 - loss: 0.3436 - val_accuracy: 0.7674 - val_loss: 0.6916\n",
            "Epoch 45/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.9043 - loss: 0.3453 - val_accuracy: 0.7604 - val_loss: 0.6592\n",
            "Epoch 46/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.9220 - loss: 0.2979 - val_accuracy: 0.7812 - val_loss: 0.6816\n",
            "Epoch 47/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 0.9152 - loss: 0.3220 - val_accuracy: 0.7986 - val_loss: 0.6564\n",
            "Epoch 48/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.9121 - loss: 0.3285 - val_accuracy: 0.7917 - val_loss: 0.6340\n",
            "Epoch 49/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.9282 - loss: 0.3141 - val_accuracy: 0.7674 - val_loss: 0.6465\n",
            "Epoch 50/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.9306 - loss: 0.2839 - val_accuracy: 0.7917 - val_loss: 0.6223\n",
            "Epoch 51/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.9209 - loss: 0.3016 - val_accuracy: 0.7604 - val_loss: 0.6062\n",
            "Epoch 52/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.9326 - loss: 0.2717 - val_accuracy: 0.8056 - val_loss: 0.6004\n",
            "Epoch 53/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 0.9431 - loss: 0.2613 - val_accuracy: 0.7986 - val_loss: 0.6068\n",
            "Epoch 54/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.9295 - loss: 0.2596 - val_accuracy: 0.8021 - val_loss: 0.6546\n",
            "Epoch 55/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.9528 - loss: 0.2445 - val_accuracy: 0.8194 - val_loss: 0.6311\n",
            "Epoch 56/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9500 - loss: 0.2167 - val_accuracy: 0.7812 - val_loss: 0.6900\n",
            "Epoch 57/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 0.9425 - loss: 0.2143 - val_accuracy: 0.7986 - val_loss: 0.5874\n",
            "Epoch 58/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9630 - loss: 0.1999 - val_accuracy: 0.8229 - val_loss: 0.5806\n",
            "Epoch 59/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9612 - loss: 0.1964 - val_accuracy: 0.8160 - val_loss: 0.6048\n",
            "Epoch 60/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9680 - loss: 0.1937 - val_accuracy: 0.7986 - val_loss: 0.6044\n",
            "Epoch 61/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.9626 - loss: 0.1851 - val_accuracy: 0.8056 - val_loss: 0.6123\n",
            "Epoch 62/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9678 - loss: 0.1786 - val_accuracy: 0.8194 - val_loss: 0.5787\n",
            "Epoch 63/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.9614 - loss: 0.1812 - val_accuracy: 0.8056 - val_loss: 0.5885\n",
            "Epoch 64/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9695 - loss: 0.1702 - val_accuracy: 0.8125 - val_loss: 0.6154\n",
            "Epoch 65/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.9657 - loss: 0.1800 - val_accuracy: 0.8090 - val_loss: 0.6297\n",
            "Epoch 66/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 0.9753 - loss: 0.1532 - val_accuracy: 0.7986 - val_loss: 0.6084\n",
            "Epoch 67/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.9766 - loss: 0.1552 - val_accuracy: 0.8125 - val_loss: 0.5809\n",
            "Epoch 68/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.9701 - loss: 0.1595 - val_accuracy: 0.8194 - val_loss: 0.6396\n",
            "Epoch 69/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9758 - loss: 0.1590 - val_accuracy: 0.8194 - val_loss: 0.5950\n",
            "Epoch 70/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.9701 - loss: 0.1445 - val_accuracy: 0.8090 - val_loss: 0.5860\n",
            "Epoch 71/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.9764 - loss: 0.1355 - val_accuracy: 0.8333 - val_loss: 0.5999\n",
            "Epoch 72/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9807 - loss: 0.1339 - val_accuracy: 0.8229 - val_loss: 0.6054\n",
            "Epoch 73/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9770 - loss: 0.1296 - val_accuracy: 0.8125 - val_loss: 0.6111\n",
            "Epoch 74/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.9814 - loss: 0.1329 - val_accuracy: 0.8333 - val_loss: 0.5580\n",
            "Epoch 75/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.9842 - loss: 0.1208 - val_accuracy: 0.8299 - val_loss: 0.5604\n",
            "Epoch 76/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.9821 - loss: 0.1205 - val_accuracy: 0.8507 - val_loss: 0.5414\n",
            "Epoch 77/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.9794 - loss: 0.1212 - val_accuracy: 0.8646 - val_loss: 0.5136\n",
            "Epoch 78/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9742 - loss: 0.1196 - val_accuracy: 0.8194 - val_loss: 0.6124\n",
            "Epoch 79/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 0.9737 - loss: 0.1235 - val_accuracy: 0.8194 - val_loss: 0.5803\n",
            "Epoch 80/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 0.9794 - loss: 0.1136 - val_accuracy: 0.8368 - val_loss: 0.5655\n",
            "Epoch 81/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9866 - loss: 0.1036 - val_accuracy: 0.8403 - val_loss: 0.5417\n",
            "Epoch 82/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.9716 - loss: 0.1096 - val_accuracy: 0.8333 - val_loss: 0.5704\n",
            "Epoch 83/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.9863 - loss: 0.1045 - val_accuracy: 0.8333 - val_loss: 0.6061\n",
            "Epoch 84/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9840 - loss: 0.1093 - val_accuracy: 0.8507 - val_loss: 0.5760\n",
            "Epoch 85/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.9870 - loss: 0.0924 - val_accuracy: 0.8472 - val_loss: 0.5464\n",
            "Epoch 86/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - accuracy: 0.9933 - loss: 0.0859 - val_accuracy: 0.8368 - val_loss: 0.5308\n",
            "Epoch 87/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.9827 - loss: 0.0917 - val_accuracy: 0.8299 - val_loss: 0.5677\n",
            "Epoch 88/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.9857 - loss: 0.0944 - val_accuracy: 0.8264 - val_loss: 0.5369\n",
            "Epoch 89/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.9797 - loss: 0.0938 - val_accuracy: 0.8403 - val_loss: 0.5426\n",
            "Epoch 90/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9827 - loss: 0.0865 - val_accuracy: 0.8542 - val_loss: 0.5527\n",
            "Epoch 91/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.9811 - loss: 0.1009 - val_accuracy: 0.8472 - val_loss: 0.5999\n",
            "Epoch 92/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.9820 - loss: 0.0890 - val_accuracy: 0.8611 - val_loss: 0.5617\n",
            "Epoch 93/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.9892 - loss: 0.0782 - val_accuracy: 0.8715 - val_loss: 0.5131\n",
            "Epoch 94/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 0.9850 - loss: 0.0913 - val_accuracy: 0.8611 - val_loss: 0.5238\n",
            "Epoch 95/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - accuracy: 0.9918 - loss: 0.0736 - val_accuracy: 0.8576 - val_loss: 0.5074\n",
            "Epoch 96/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9903 - loss: 0.0750 - val_accuracy: 0.8576 - val_loss: 0.5118\n",
            "Epoch 97/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.9866 - loss: 0.0868 - val_accuracy: 0.8542 - val_loss: 0.5311\n",
            "Epoch 98/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9956 - loss: 0.0582 - val_accuracy: 0.8542 - val_loss: 0.4995\n",
            "Epoch 99/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - accuracy: 0.9889 - loss: 0.0777 - val_accuracy: 0.8681 - val_loss: 0.4950\n",
            "Epoch 100/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.9970 - loss: 0.0661 - val_accuracy: 0.8681 - val_loss: 0.4789\n"
          ]
        }
      ],
      "source": [
        "# Training the model with attention\n",
        "history_attention = model_with_attention.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhhvU-liIwF6"
      },
      "source": [
        "### Parameter tunning using optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msyt_rD4G8gf",
        "outputId": "49d98b70-201a-4aa2-a9f4-feef0dea6b2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIhhHoG3G8dQ"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok5t5xznG8Wa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17pNXOBYG8TY"
      },
      "outputs": [],
      "source": [
        "#Attention alyer\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1), initializer=\"normal\")\n",
        "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1), initializer=\"zeros\")\n",
        "        super(Attention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
        "        a = tf.keras.backend.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return tf.keras.backend.sum(output, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9vxd1jPHU0K"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # Hyperparameters to tune\n",
        "    lstm_units_1 = trial.suggest_int('lstm_units_1', 128, 512)\n",
        "    lstm_units_2 = trial.suggest_int('lstm_units_2', 64, 256)\n",
        "    dense_units = trial.suggest_int('dense_units', 32, 128)\n",
        "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
        "\n",
        "    # Build model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add LSTM layers\n",
        "    model.add(LSTM(lstm_units_1, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    model.add(LSTM(lstm_units_2, return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Add Attention layer\n",
        "    model.add(Attention())\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(dense_units, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(dense_units, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=20,  # Use a smaller number for Optuna trials\n",
        "                        batch_size=64,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        verbose=0)  # Don't print the training logs for each trial\n",
        "\n",
        "    # Return the validation accuracy of the last epoch\n",
        "    val_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "    return val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lo8tRa2HZUm",
        "outputId": "a2d024d2-31b0-440b-cfbd-3f00bde4f901"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-09-28 04:22:27,725] A new study created in memory with name: no-name-2ceb6e65-0d5e-4ce3-b56b-a022da741098\n",
            "[I 2024-09-28 05:43:10,032] Trial 0 finished with value: 0.5729166865348816 and parameters: {'lstm_units_1': 512, 'lstm_units_2': 113, 'dense_units': 91, 'dropout_rate': 0.24579098903111718, 'learning_rate': 6.792140693083467e-05}. Best is trial 0 with value: 0.5729166865348816.\n",
            "[I 2024-09-28 06:29:15,523] Trial 1 finished with value: 0.2395833283662796 and parameters: {'lstm_units_1': 426, 'lstm_units_2': 105, 'dense_units': 42, 'dropout_rate': 0.4039495492397093, 'learning_rate': 1.1657260710844488e-05}. Best is trial 0 with value: 0.5729166865348816.\n",
            "[I 2024-09-28 07:21:41,874] Trial 2 finished with value: 0.2743055522441864 and parameters: {'lstm_units_1': 441, 'lstm_units_2': 165, 'dense_units': 121, 'dropout_rate': 0.30387721400110324, 'learning_rate': 1.4052990505706368e-05}. Best is trial 0 with value: 0.5729166865348816.\n",
            "[I 2024-09-28 08:28:16,110] Trial 3 finished with value: 0.6458333134651184 and parameters: {'lstm_units_1': 458, 'lstm_units_2': 250, 'dense_units': 102, 'dropout_rate': 0.27427073983367506, 'learning_rate': 0.00021989031669565317}. Best is trial 3 with value: 0.6458333134651184.\n"
          ]
        }
      ],
      "source": [
        "# Create a study and optimize the hyperparameters\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2ENDfumHfNB"
      },
      "outputs": [],
      "source": [
        "# Get the best trial and its parameters\n",
        "print('Best trial:')\n",
        "trial = study.best_trial\n",
        "print(f'  Validation Accuracy: {trial.value}')\n",
        "print('  Best hyperparameters: ', trial.params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiWugUBWHkcJ"
      },
      "outputs": [],
      "source": [
        "# Rebuild the model using the best parameters found by Optuna\n",
        "best_model = Sequential()\n",
        "\n",
        "# Add LSTM layers\n",
        "best_model.add(LSTM(trial.params['lstm_units_1'], return_sequences=True, input_shape=input_shape))\n",
        "best_model.add(BatchNormalization())\n",
        "best_model.add(Dropout(trial.params['dropout_rate']))\n",
        "\n",
        "best_model.add(LSTM(trial.params['lstm_units_2'], return_sequences=True))\n",
        "best_model.add(BatchNormalization())\n",
        "best_model.add(Dropout(trial.params['dropout_rate']))\n",
        "\n",
        "# Add Attention layer\n",
        "best_model.add(Attention())\n",
        "\n",
        "# Fully connected layers\n",
        "best_model.add(Dense(trial.params['dense_units'], activation='relu'))\n",
        "best_model.add(BatchNormalization())\n",
        "best_model.add(Dropout(trial.params['dropout_rate']))\n",
        "best_model.add(Dense(trial.params['dense_units'], activation='relu'))\n",
        "best_model.add(BatchNormalization())\n",
        "best_model.add(Dropout(trial.params['dropout_rate']))\n",
        "\n",
        "# Output layer\n",
        "best_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the best model\n",
        "best_optimizer = Adam(learning_rate=trial.params['learning_rate'])\n",
        "best_model.compile(optimizer=best_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the best model on the entire dataset\n",
        "best_model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DClx43Urdd_A"
      },
      "source": [
        "### LSTM without Attenstion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxbiNlz9dh42"
      },
      "outputs": [],
      "source": [
        "def build_lstm_attention_model1(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add LSTM layers\n",
        "    model.add(LSTM(512, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(LSTM(128))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimozer=Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimozer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "ZNOBNlVSd3XR",
        "outputId": "91216fa8-53bf-40f9-ac12-4c2df3bf9a42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,130,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">328,192</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_12               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m1,130,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m328,192\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_12               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,474,696</span> (5.63 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,474,696\u001b[0m (5.63 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,473,160</span> (5.62 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,473,160\u001b[0m (5.62 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model summary\n",
        "model_without_attention = build_lstm_attention_model1(input_shape, num_classes)\n",
        "model_without_attention.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yCPZyb1eUfS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "y_train = np.argmax(y_train, axis=1)\n",
        "y_test = np.argmax(y_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6vV5blAd8Zz",
        "outputId": "e11769d8-8182-475d-ce5c-7b36c2ea63df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.1154 - loss: 3.0917 - val_accuracy: 0.1562 - val_loss: 2.0669\n",
            "Epoch 2/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.1508 - loss: 2.6638 - val_accuracy: 0.2326 - val_loss: 2.0478\n",
            "Epoch 3/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 0.1752 - loss: 2.6490 - val_accuracy: 0.2604 - val_loss: 2.0349\n",
            "Epoch 4/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.2091 - loss: 2.4439 - val_accuracy: 0.2569 - val_loss: 2.0232\n",
            "Epoch 5/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.2323 - loss: 2.3565 - val_accuracy: 0.2917 - val_loss: 2.0115\n",
            "Epoch 6/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.2159 - loss: 2.2946 - val_accuracy: 0.2708 - val_loss: 1.9973\n",
            "Epoch 7/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.2455 - loss: 2.2355 - val_accuracy: 0.3125 - val_loss: 1.9810\n",
            "Epoch 8/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.2614 - loss: 2.2699 - val_accuracy: 0.3090 - val_loss: 1.9653\n",
            "Epoch 9/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.2532 - loss: 2.1886 - val_accuracy: 0.3368 - val_loss: 1.9283\n",
            "Epoch 10/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.2803 - loss: 2.1140 - val_accuracy: 0.3333 - val_loss: 1.9045\n",
            "Epoch 11/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.3080 - loss: 2.0724 - val_accuracy: 0.3611 - val_loss: 1.8696\n",
            "Epoch 12/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.2923 - loss: 2.0663 - val_accuracy: 0.3160 - val_loss: 1.8373\n",
            "Epoch 13/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - accuracy: 0.3112 - loss: 2.1859 - val_accuracy: 0.3021 - val_loss: 1.8469\n",
            "Epoch 14/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.3037 - loss: 2.0056 - val_accuracy: 0.3194 - val_loss: 1.7971\n",
            "Epoch 15/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.3590 - loss: 1.9033 - val_accuracy: 0.3333 - val_loss: 1.7912\n",
            "Epoch 16/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.3292 - loss: 2.0176 - val_accuracy: 0.3368 - val_loss: 1.7530\n",
            "Epoch 17/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.3411 - loss: 1.9553 - val_accuracy: 0.3611 - val_loss: 1.7470\n",
            "Epoch 18/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.3165 - loss: 2.0366 - val_accuracy: 0.3542 - val_loss: 1.7210\n",
            "Epoch 19/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.3685 - loss: 1.8513 - val_accuracy: 0.3611 - val_loss: 1.6658\n",
            "Epoch 20/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.3470 - loss: 1.8673 - val_accuracy: 0.3715 - val_loss: 1.6460\n",
            "Epoch 21/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.3564 - loss: 1.8502 - val_accuracy: 0.3924 - val_loss: 1.6248\n",
            "Epoch 22/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 0.3506 - loss: 1.8179 - val_accuracy: 0.3819 - val_loss: 1.6672\n",
            "Epoch 23/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.3533 - loss: 1.8259 - val_accuracy: 0.4028 - val_loss: 1.6879\n",
            "Epoch 24/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.3645 - loss: 1.7941 - val_accuracy: 0.4167 - val_loss: 1.6911\n",
            "Epoch 25/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.3360 - loss: 1.8137 - val_accuracy: 0.3819 - val_loss: 1.6880\n",
            "Epoch 26/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 0.3757 - loss: 1.7598 - val_accuracy: 0.3750 - val_loss: 1.6419\n",
            "Epoch 27/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.3694 - loss: 1.8111 - val_accuracy: 0.3229 - val_loss: 1.9087\n",
            "Epoch 28/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.3826 - loss: 1.7389 - val_accuracy: 0.4062 - val_loss: 1.5990\n",
            "Epoch 29/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.3901 - loss: 1.7211 - val_accuracy: 0.3958 - val_loss: 1.6145\n",
            "Epoch 30/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.3921 - loss: 1.7087 - val_accuracy: 0.4097 - val_loss: 1.5685\n",
            "Epoch 31/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.4186 - loss: 1.6889 - val_accuracy: 0.4097 - val_loss: 1.5463\n",
            "Epoch 32/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 0.4064 - loss: 1.6904 - val_accuracy: 0.3889 - val_loss: 1.6030\n",
            "Epoch 33/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.3793 - loss: 1.7598 - val_accuracy: 0.4028 - val_loss: 1.6100\n",
            "Epoch 34/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.4150 - loss: 1.6612 - val_accuracy: 0.4028 - val_loss: 1.6034\n",
            "Epoch 35/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.4157 - loss: 1.6559 - val_accuracy: 0.4514 - val_loss: 1.5997\n",
            "Epoch 36/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4450 - loss: 1.5774 - val_accuracy: 0.4201 - val_loss: 1.5880\n",
            "Epoch 37/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.4580 - loss: 1.5568 - val_accuracy: 0.4236 - val_loss: 1.6443\n",
            "Epoch 38/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.4518 - loss: 1.6066 - val_accuracy: 0.4375 - val_loss: 1.5420\n",
            "Epoch 39/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4379 - loss: 1.5886 - val_accuracy: 0.3889 - val_loss: 1.6118\n",
            "Epoch 40/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4563 - loss: 1.5241 - val_accuracy: 0.3785 - val_loss: 1.6833\n",
            "Epoch 41/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.4522 - loss: 1.5517 - val_accuracy: 0.4201 - val_loss: 1.5783\n",
            "Epoch 42/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - accuracy: 0.4196 - loss: 1.5744 - val_accuracy: 0.4132 - val_loss: 1.6538\n",
            "Epoch 43/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.4192 - loss: 1.5389 - val_accuracy: 0.4479 - val_loss: 1.5081\n",
            "Epoch 44/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.4361 - loss: 1.6049 - val_accuracy: 0.4340 - val_loss: 1.6046\n",
            "Epoch 45/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - accuracy: 0.4420 - loss: 1.5270 - val_accuracy: 0.4271 - val_loss: 1.5616\n",
            "Epoch 46/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4391 - loss: 1.4854 - val_accuracy: 0.4514 - val_loss: 1.5380\n",
            "Epoch 47/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.4781 - loss: 1.4700 - val_accuracy: 0.4688 - val_loss: 1.5152\n",
            "Epoch 48/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.4966 - loss: 1.4556 - val_accuracy: 0.4549 - val_loss: 1.5375\n",
            "Epoch 49/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4827 - loss: 1.5041 - val_accuracy: 0.4549 - val_loss: 1.5698\n",
            "Epoch 50/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4662 - loss: 1.4693 - val_accuracy: 0.4375 - val_loss: 1.5049\n",
            "Epoch 51/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.4548 - loss: 1.4549 - val_accuracy: 0.4757 - val_loss: 1.5304\n",
            "Epoch 52/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4573 - loss: 1.5112 - val_accuracy: 0.4444 - val_loss: 1.5081\n",
            "Epoch 53/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4765 - loss: 1.4886 - val_accuracy: 0.4826 - val_loss: 1.4732\n",
            "Epoch 54/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4690 - loss: 1.4851 - val_accuracy: 0.4896 - val_loss: 1.4915\n",
            "Epoch 55/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.4911 - loss: 1.3837 - val_accuracy: 0.4410 - val_loss: 1.5285\n",
            "Epoch 56/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.4871 - loss: 1.4300 - val_accuracy: 0.4028 - val_loss: 1.6798\n",
            "Epoch 57/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4771 - loss: 1.4604 - val_accuracy: 0.4792 - val_loss: 1.5627\n",
            "Epoch 58/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.4916 - loss: 1.3858 - val_accuracy: 0.4826 - val_loss: 1.4820\n",
            "Epoch 59/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5069 - loss: 1.3673 - val_accuracy: 0.4722 - val_loss: 1.4712\n",
            "Epoch 60/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.5207 - loss: 1.3639 - val_accuracy: 0.5139 - val_loss: 1.4344\n",
            "Epoch 61/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - accuracy: 0.4894 - loss: 1.4017 - val_accuracy: 0.4479 - val_loss: 1.4662\n",
            "Epoch 62/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.4932 - loss: 1.4291 - val_accuracy: 0.4653 - val_loss: 1.4513\n",
            "Epoch 63/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.5191 - loss: 1.3836 - val_accuracy: 0.4722 - val_loss: 1.4494\n",
            "Epoch 64/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.4928 - loss: 1.3786 - val_accuracy: 0.4861 - val_loss: 1.4999\n",
            "Epoch 65/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5100 - loss: 1.3685 - val_accuracy: 0.4618 - val_loss: 1.5375\n",
            "Epoch 66/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.5114 - loss: 1.3490 - val_accuracy: 0.4757 - val_loss: 1.4925\n",
            "Epoch 67/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.5289 - loss: 1.3063 - val_accuracy: 0.4826 - val_loss: 1.4824\n",
            "Epoch 68/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5205 - loss: 1.3142 - val_accuracy: 0.4826 - val_loss: 1.4198\n",
            "Epoch 69/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5496 - loss: 1.2466 - val_accuracy: 0.4826 - val_loss: 1.4290\n",
            "Epoch 70/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.5137 - loss: 1.3344 - val_accuracy: 0.4757 - val_loss: 1.5212\n",
            "Epoch 71/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.5482 - loss: 1.2212 - val_accuracy: 0.4688 - val_loss: 1.4430\n",
            "Epoch 72/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - accuracy: 0.5341 - loss: 1.2951 - val_accuracy: 0.5035 - val_loss: 1.4468\n",
            "Epoch 73/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5645 - loss: 1.2183 - val_accuracy: 0.5347 - val_loss: 1.4179\n",
            "Epoch 74/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.5624 - loss: 1.2635 - val_accuracy: 0.4549 - val_loss: 1.5809\n",
            "Epoch 75/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.5474 - loss: 1.2178 - val_accuracy: 0.5312 - val_loss: 1.3897\n",
            "Epoch 76/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.5654 - loss: 1.2693 - val_accuracy: 0.4757 - val_loss: 1.4663\n",
            "Epoch 77/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5274 - loss: 1.2833 - val_accuracy: 0.5139 - val_loss: 1.4113\n",
            "Epoch 78/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5299 - loss: 1.2484 - val_accuracy: 0.5069 - val_loss: 1.4626\n",
            "Epoch 79/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.5721 - loss: 1.2002 - val_accuracy: 0.4757 - val_loss: 1.5094\n",
            "Epoch 80/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.5727 - loss: 1.1873 - val_accuracy: 0.5243 - val_loss: 1.4523\n",
            "Epoch 81/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.5678 - loss: 1.2081 - val_accuracy: 0.4965 - val_loss: 1.4067\n",
            "Epoch 82/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.5486 - loss: 1.2092 - val_accuracy: 0.4965 - val_loss: 1.4313\n",
            "Epoch 83/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.5611 - loss: 1.2179 - val_accuracy: 0.4965 - val_loss: 1.3881\n",
            "Epoch 84/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - accuracy: 0.5848 - loss: 1.1364 - val_accuracy: 0.4757 - val_loss: 1.5510\n",
            "Epoch 85/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - accuracy: 0.5875 - loss: 1.2132 - val_accuracy: 0.4826 - val_loss: 1.5488\n",
            "Epoch 86/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 227ms/step - accuracy: 0.5955 - loss: 1.1309 - val_accuracy: 0.5035 - val_loss: 1.3925\n",
            "Epoch 87/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.5634 - loss: 1.2389 - val_accuracy: 0.5278 - val_loss: 1.3944\n",
            "Epoch 88/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - accuracy: 0.5899 - loss: 1.1371 - val_accuracy: 0.4688 - val_loss: 1.5129\n",
            "Epoch 89/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - accuracy: 0.5474 - loss: 1.2151 - val_accuracy: 0.5104 - val_loss: 1.5374\n",
            "Epoch 90/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.5301 - loss: 1.3054 - val_accuracy: 0.5278 - val_loss: 1.4309\n",
            "Epoch 91/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5897 - loss: 1.1363 - val_accuracy: 0.5174 - val_loss: 1.4043\n",
            "Epoch 92/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.5836 - loss: 1.1313 - val_accuracy: 0.4931 - val_loss: 1.4069\n",
            "Epoch 93/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.5964 - loss: 1.1670 - val_accuracy: 0.5278 - val_loss: 1.3840\n",
            "Epoch 94/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - accuracy: 0.6161 - loss: 1.0987 - val_accuracy: 0.5243 - val_loss: 1.3697\n",
            "Epoch 95/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - accuracy: 0.6047 - loss: 1.0960 - val_accuracy: 0.5347 - val_loss: 1.3422\n",
            "Epoch 96/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.6092 - loss: 1.0691 - val_accuracy: 0.5000 - val_loss: 1.3980\n",
            "Epoch 97/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.6022 - loss: 1.1279 - val_accuracy: 0.5382 - val_loss: 1.3697\n",
            "Epoch 98/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - accuracy: 0.6167 - loss: 1.1018 - val_accuracy: 0.5174 - val_loss: 1.5732\n",
            "Epoch 99/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 148ms/step - accuracy: 0.5855 - loss: 1.1784 - val_accuracy: 0.5312 - val_loss: 1.4127\n",
            "Epoch 100/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.5863 - loss: 1.0735 - val_accuracy: 0.5590 - val_loss: 1.3591\n"
          ]
        }
      ],
      "source": [
        "# Training the model with attention\n",
        "history_attention = model_without_attention.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we_aa7o6eBiI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqzogPiGHLkh"
      },
      "source": [
        "### LSTM GRU with attenstion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0KjZo80HPZr"
      },
      "outputs": [],
      "source": [
        "def build_lstm_attention_model2(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add LSTM layers\n",
        "    model.add(LSTM(512, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "    model.add(GRU(412, activation='relu', return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(LSTM(312, return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(LSTM(256, return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Add Attention layer\n",
        "    model.add(Attention())\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimozer=Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimozer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "V9pos-DtHXWy",
        "outputId": "eeb76c4d-eca5-4b51-ed59-0d1fe79ecb44"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,130,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,144,536</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,648</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">904,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,248</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">582,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_18               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_19               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_20               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m1,130,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m412\u001b[0m)            │       \u001b[38;5;34m1,144,536\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m412\u001b[0m)            │           \u001b[38;5;34m1,648\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m412\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m312\u001b[0m)            │         \u001b[38;5;34m904,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m312\u001b[0m)            │           \u001b[38;5;34m1,248\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m312\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m582,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_18               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_1 (\u001b[38;5;33mAttention\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │             \u001b[38;5;34m656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_19               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_20               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,811,552</span> (14.54 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,811,552\u001b[0m (14.54 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,808,184</span> (14.53 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,808,184\u001b[0m (14.53 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,368</span> (13.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,368\u001b[0m (13.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model summary\n",
        "model_with_attention = build_lstm_attention_model2(input_shape, num_classes)\n",
        "model_with_attention.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbBxKA6vHdg3",
        "outputId": "95eab400-512c-40e3-ab3f-c56786f99ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 925ms/step - accuracy: 0.1163 - loss: 2.9479 - val_accuracy: 0.1181 - val_loss: 2.0999\n",
            "Epoch 2/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 908ms/step - accuracy: 0.2906 - loss: 2.2016 - val_accuracy: 0.1181 - val_loss: 2.1290\n",
            "Epoch 3/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 968ms/step - accuracy: 0.3243 - loss: 1.8551 - val_accuracy: 0.1840 - val_loss: 2.1566\n",
            "Epoch 4/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 921ms/step - accuracy: 0.4034 - loss: 1.6134 - val_accuracy: 0.1458 - val_loss: 2.1777\n",
            "Epoch 5/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 844ms/step - accuracy: 0.4601 - loss: 1.4890 - val_accuracy: 0.1111 - val_loss: 2.1931\n",
            "Epoch 6/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 851ms/step - accuracy: 0.5091 - loss: 1.3810 - val_accuracy: 0.1076 - val_loss: 2.2221\n",
            "Epoch 7/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 847ms/step - accuracy: 0.5453 - loss: 1.2626 - val_accuracy: 0.0938 - val_loss: 2.2407\n",
            "Epoch 8/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 842ms/step - accuracy: 0.5972 - loss: 1.1231 - val_accuracy: 0.1076 - val_loss: 2.2637\n",
            "Epoch 9/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 829ms/step - accuracy: 0.6102 - loss: 1.0823 - val_accuracy: 0.1181 - val_loss: 2.2919\n",
            "Epoch 10/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 981ms/step - accuracy: 0.6632 - loss: 0.9800 - val_accuracy: 0.1042 - val_loss: 2.3091\n",
            "Epoch 11/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.6867 - loss: 0.8987 - val_accuracy: 0.0938 - val_loss: 2.4348\n",
            "Epoch 12/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 841ms/step - accuracy: 0.7419 - loss: 0.8038 - val_accuracy: 0.0938 - val_loss: 2.5370\n",
            "Epoch 13/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 855ms/step - accuracy: 0.7501 - loss: 0.7666 - val_accuracy: 0.1042 - val_loss: 2.5696\n",
            "Epoch 14/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 842ms/step - accuracy: 0.7396 - loss: 0.7583 - val_accuracy: 0.0938 - val_loss: 2.6346\n",
            "Epoch 15/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 936ms/step - accuracy: 0.7837 - loss: 0.6537 - val_accuracy: 0.1285 - val_loss: 2.6102\n",
            "Epoch 16/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - accuracy: 0.7981 - loss: 0.6153 - val_accuracy: 0.1840 - val_loss: 2.5563\n",
            "Epoch 17/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 840ms/step - accuracy: 0.8106 - loss: 0.6026 - val_accuracy: 0.1806 - val_loss: 2.6023\n",
            "Epoch 18/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 832ms/step - accuracy: 0.8101 - loss: 0.5842 - val_accuracy: 0.1736 - val_loss: 2.7144\n",
            "Epoch 19/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 960ms/step - accuracy: 0.8628 - loss: 0.4823 - val_accuracy: 0.1979 - val_loss: 2.7582\n",
            "Epoch 20/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 815ms/step - accuracy: 0.8388 - loss: 0.5274 - val_accuracy: 0.2326 - val_loss: 2.8018\n",
            "Epoch 21/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.8818 - loss: 0.4278 - val_accuracy: 0.2569 - val_loss: 2.6849\n",
            "Epoch 22/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 845ms/step - accuracy: 0.9043 - loss: 0.3967 - val_accuracy: 0.2743 - val_loss: 2.6304\n",
            "Epoch 23/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 910ms/step - accuracy: 0.9053 - loss: 0.3778 - val_accuracy: 0.2882 - val_loss: 2.4441\n",
            "Epoch 24/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 845ms/step - accuracy: 0.9259 - loss: 0.3251 - val_accuracy: 0.3229 - val_loss: 2.2489\n",
            "Epoch 25/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 911ms/step - accuracy: 0.9181 - loss: 0.3313 - val_accuracy: 0.3681 - val_loss: 2.0439\n",
            "Epoch 26/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 834ms/step - accuracy: 0.9215 - loss: 0.3106 - val_accuracy: 0.4167 - val_loss: 1.7719\n",
            "Epoch 27/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 833ms/step - accuracy: 0.9262 - loss: 0.2910 - val_accuracy: 0.4861 - val_loss: 1.4496\n",
            "Epoch 28/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 835ms/step - accuracy: 0.9358 - loss: 0.2887 - val_accuracy: 0.5104 - val_loss: 1.4568\n",
            "Epoch 29/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 980ms/step - accuracy: 0.9466 - loss: 0.2612 - val_accuracy: 0.5868 - val_loss: 1.2442\n",
            "Epoch 30/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 833ms/step - accuracy: 0.9438 - loss: 0.2519 - val_accuracy: 0.6215 - val_loss: 1.1177\n",
            "Epoch 31/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 840ms/step - accuracy: 0.9637 - loss: 0.2124 - val_accuracy: 0.6215 - val_loss: 1.0357\n",
            "Epoch 32/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 894ms/step - accuracy: 0.9490 - loss: 0.2241 - val_accuracy: 0.6597 - val_loss: 0.9447\n",
            "Epoch 33/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 830ms/step - accuracy: 0.9537 - loss: 0.2141 - val_accuracy: 0.6597 - val_loss: 0.9758\n",
            "Epoch 34/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 845ms/step - accuracy: 0.9631 - loss: 0.2077 - val_accuracy: 0.6806 - val_loss: 0.9042\n",
            "Epoch 35/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 835ms/step - accuracy: 0.9718 - loss: 0.1754 - val_accuracy: 0.7361 - val_loss: 0.7843\n",
            "Epoch 36/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 842ms/step - accuracy: 0.9650 - loss: 0.1821 - val_accuracy: 0.7743 - val_loss: 0.7354\n",
            "Epoch 37/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 836ms/step - accuracy: 0.9655 - loss: 0.1629 - val_accuracy: 0.7639 - val_loss: 0.6867\n",
            "Epoch 38/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 845ms/step - accuracy: 0.9739 - loss: 0.1593 - val_accuracy: 0.7535 - val_loss: 0.6622\n",
            "Epoch 39/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 841ms/step - accuracy: 0.9768 - loss: 0.1427 - val_accuracy: 0.7535 - val_loss: 0.6551\n",
            "Epoch 40/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 913ms/step - accuracy: 0.9677 - loss: 0.1713 - val_accuracy: 0.7535 - val_loss: 0.6850\n",
            "Epoch 41/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 853ms/step - accuracy: 0.9817 - loss: 0.1295 - val_accuracy: 0.7604 - val_loss: 0.6530\n",
            "Epoch 42/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 848ms/step - accuracy: 0.9796 - loss: 0.1325 - val_accuracy: 0.7812 - val_loss: 0.6360\n",
            "Epoch 43/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 838ms/step - accuracy: 0.9900 - loss: 0.1160 - val_accuracy: 0.7778 - val_loss: 0.6188\n",
            "Epoch 44/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 839ms/step - accuracy: 0.9806 - loss: 0.1187 - val_accuracy: 0.7708 - val_loss: 0.6388\n",
            "Epoch 45/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 845ms/step - accuracy: 0.9934 - loss: 0.0965 - val_accuracy: 0.8056 - val_loss: 0.5854\n",
            "Epoch 46/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 856ms/step - accuracy: 0.9769 - loss: 0.1209 - val_accuracy: 0.8090 - val_loss: 0.6079\n",
            "Epoch 47/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 855ms/step - accuracy: 0.9868 - loss: 0.1034 - val_accuracy: 0.7882 - val_loss: 0.6234\n",
            "Epoch 48/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 852ms/step - accuracy: 0.9884 - loss: 0.1153 - val_accuracy: 0.8194 - val_loss: 0.5440\n",
            "Epoch 49/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 898ms/step - accuracy: 0.9802 - loss: 0.1059 - val_accuracy: 0.8333 - val_loss: 0.4756\n",
            "Epoch 50/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 851ms/step - accuracy: 0.9907 - loss: 0.0928 - val_accuracy: 0.8264 - val_loss: 0.5303\n",
            "Epoch 51/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 903ms/step - accuracy: 0.9901 - loss: 0.0888 - val_accuracy: 0.8125 - val_loss: 0.5453\n",
            "Epoch 52/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 839ms/step - accuracy: 0.9797 - loss: 0.1106 - val_accuracy: 0.8264 - val_loss: 0.5060\n",
            "Epoch 53/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 839ms/step - accuracy: 0.9875 - loss: 0.0859 - val_accuracy: 0.8229 - val_loss: 0.5169\n",
            "Epoch 54/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 854ms/step - accuracy: 0.9799 - loss: 0.1139 - val_accuracy: 0.8333 - val_loss: 0.4997\n",
            "Epoch 55/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 850ms/step - accuracy: 0.9965 - loss: 0.0761 - val_accuracy: 0.8125 - val_loss: 0.5190\n",
            "Epoch 56/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 842ms/step - accuracy: 0.9891 - loss: 0.0825 - val_accuracy: 0.7951 - val_loss: 0.5881\n",
            "Epoch 57/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 844ms/step - accuracy: 0.9872 - loss: 0.0814 - val_accuracy: 0.8160 - val_loss: 0.5423\n",
            "Epoch 58/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 850ms/step - accuracy: 0.9935 - loss: 0.0652 - val_accuracy: 0.8507 - val_loss: 0.4582\n",
            "Epoch 59/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 857ms/step - accuracy: 0.9904 - loss: 0.0634 - val_accuracy: 0.8229 - val_loss: 0.5284\n",
            "Epoch 60/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 859ms/step - accuracy: 0.9885 - loss: 0.0739 - val_accuracy: 0.8090 - val_loss: 0.5119\n",
            "Epoch 61/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 852ms/step - accuracy: 0.9906 - loss: 0.0764 - val_accuracy: 0.8090 - val_loss: 0.5088\n",
            "Epoch 62/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 843ms/step - accuracy: 0.9993 - loss: 0.0609 - val_accuracy: 0.8299 - val_loss: 0.5061\n",
            "Epoch 63/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 852ms/step - accuracy: 0.9979 - loss: 0.0577 - val_accuracy: 0.8194 - val_loss: 0.5198\n",
            "Epoch 64/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 850ms/step - accuracy: 0.9968 - loss: 0.0597 - val_accuracy: 0.8160 - val_loss: 0.5537\n",
            "Epoch 65/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 856ms/step - accuracy: 0.9948 - loss: 0.0592 - val_accuracy: 0.8056 - val_loss: 0.5096\n",
            "Epoch 66/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 904ms/step - accuracy: 0.9992 - loss: 0.0482 - val_accuracy: 0.8507 - val_loss: 0.4528\n",
            "Epoch 67/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 843ms/step - accuracy: 0.9968 - loss: 0.0592 - val_accuracy: 0.8194 - val_loss: 0.4948\n",
            "Epoch 68/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 856ms/step - accuracy: 0.9949 - loss: 0.0583 - val_accuracy: 0.8160 - val_loss: 0.5158\n",
            "Epoch 69/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 851ms/step - accuracy: 0.9967 - loss: 0.0509 - val_accuracy: 0.8403 - val_loss: 0.4786\n",
            "Epoch 70/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 855ms/step - accuracy: 0.9962 - loss: 0.0504 - val_accuracy: 0.8229 - val_loss: 0.4787\n",
            "Epoch 71/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 835ms/step - accuracy: 0.9991 - loss: 0.0475 - val_accuracy: 0.8160 - val_loss: 0.5590\n",
            "Epoch 72/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 850ms/step - accuracy: 0.9923 - loss: 0.0501 - val_accuracy: 0.8299 - val_loss: 0.5497\n",
            "Epoch 73/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 839ms/step - accuracy: 0.9995 - loss: 0.0392 - val_accuracy: 0.8438 - val_loss: 0.5262\n",
            "Epoch 74/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 844ms/step - accuracy: 0.9999 - loss: 0.0418 - val_accuracy: 0.8194 - val_loss: 0.5289\n",
            "Epoch 75/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 847ms/step - accuracy: 0.9988 - loss: 0.0405 - val_accuracy: 0.8368 - val_loss: 0.4962\n",
            "Epoch 76/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 843ms/step - accuracy: 0.9980 - loss: 0.0378 - val_accuracy: 0.8438 - val_loss: 0.4705\n",
            "Epoch 77/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 851ms/step - accuracy: 0.9916 - loss: 0.0526 - val_accuracy: 0.8403 - val_loss: 0.4867\n",
            "Epoch 78/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 834ms/step - accuracy: 0.9951 - loss: 0.0445 - val_accuracy: 0.8472 - val_loss: 0.5018\n",
            "Epoch 79/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 855ms/step - accuracy: 0.9989 - loss: 0.0364 - val_accuracy: 0.8403 - val_loss: 0.5117\n",
            "Epoch 80/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 834ms/step - accuracy: 0.9994 - loss: 0.0402 - val_accuracy: 0.8333 - val_loss: 0.4764\n",
            "Epoch 81/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 835ms/step - accuracy: 0.9967 - loss: 0.0363 - val_accuracy: 0.8576 - val_loss: 0.4629\n",
            "Epoch 82/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 823ms/step - accuracy: 0.9998 - loss: 0.0365 - val_accuracy: 0.8264 - val_loss: 0.5165\n",
            "Epoch 83/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 840ms/step - accuracy: 0.9966 - loss: 0.0356 - val_accuracy: 0.8090 - val_loss: 0.5895\n",
            "Epoch 84/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 827ms/step - accuracy: 0.9966 - loss: 0.0372 - val_accuracy: 0.8264 - val_loss: 0.5233\n",
            "Epoch 85/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 922ms/step - accuracy: 0.9983 - loss: 0.0314 - val_accuracy: 0.8542 - val_loss: 0.4521\n",
            "Epoch 86/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 849ms/step - accuracy: 1.0000 - loss: 0.0347 - val_accuracy: 0.8576 - val_loss: 0.4594\n",
            "Epoch 87/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 839ms/step - accuracy: 0.9997 - loss: 0.0303 - val_accuracy: 0.8438 - val_loss: 0.4831\n",
            "Epoch 88/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 831ms/step - accuracy: 0.9990 - loss: 0.0352 - val_accuracy: 0.8125 - val_loss: 0.5257\n",
            "Epoch 89/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 897ms/step - accuracy: 1.0000 - loss: 0.0289 - val_accuracy: 0.8542 - val_loss: 0.4661\n",
            "Epoch 90/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 848ms/step - accuracy: 0.9965 - loss: 0.0312 - val_accuracy: 0.8681 - val_loss: 0.4439\n",
            "Epoch 91/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 898ms/step - accuracy: 0.9960 - loss: 0.0289 - val_accuracy: 0.8576 - val_loss: 0.4357\n",
            "Epoch 92/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 838ms/step - accuracy: 0.9953 - loss: 0.0303 - val_accuracy: 0.8264 - val_loss: 0.5135\n",
            "Epoch 93/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 882ms/step - accuracy: 1.0000 - loss: 0.0255 - val_accuracy: 0.8229 - val_loss: 0.4998\n",
            "Epoch 94/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 834ms/step - accuracy: 0.9990 - loss: 0.0262 - val_accuracy: 0.8472 - val_loss: 0.4469\n",
            "Epoch 95/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 843ms/step - accuracy: 0.9966 - loss: 0.0300 - val_accuracy: 0.8368 - val_loss: 0.4725\n",
            "Epoch 96/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 844ms/step - accuracy: 0.9996 - loss: 0.0264 - val_accuracy: 0.8368 - val_loss: 0.4820\n",
            "Epoch 97/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 845ms/step - accuracy: 0.9995 - loss: 0.0298 - val_accuracy: 0.8299 - val_loss: 0.5049\n",
            "Epoch 98/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 849ms/step - accuracy: 0.9995 - loss: 0.0266 - val_accuracy: 0.8299 - val_loss: 0.5014\n",
            "Epoch 99/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 845ms/step - accuracy: 0.9990 - loss: 0.0234 - val_accuracy: 0.8576 - val_loss: 0.4359\n",
            "Epoch 100/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 930ms/step - accuracy: 0.9970 - loss: 0.0266 - val_accuracy: 0.8438 - val_loss: 0.4617\n"
          ]
        }
      ],
      "source": [
        "# Training the model with attention\n",
        "history_attention = model_with_attention.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyYw2TflQvWT"
      },
      "source": [
        "### GRU with attenstion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F52Ups19IA8t"
      },
      "outputs": [],
      "source": [
        "def build_lstm_attention_model4(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add GRU layers\n",
        "    model.add(GRU(512, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(GRU(128, return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Add Attention layer\n",
        "    model.add(Attention())\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimozer=Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimozer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "LqDG1vwfQ5LE",
        "outputId": "808d7310-5be0-4d87-e778-d22865d4bd59"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">849,408</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_21               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">246,528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_22               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_23               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_24               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m849,408\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_21               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m246,528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_22               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_2 (\u001b[38;5;33mAttention\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_23               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_24               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,112,472</span> (4.24 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,112,472\u001b[0m (4.24 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,110,936</span> (4.24 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,110,936\u001b[0m (4.24 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model summary\n",
        "model_with_attention = build_lstm_attention_model4(input_shape, num_classes)\n",
        "model_with_attention.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As6kX4-rREmL",
        "outputId": "39b4492e-c839-42b1-feb0-861ccc7cdf16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.1469 - loss: 2.8860 - val_accuracy: 0.1493 - val_loss: 2.0726\n",
            "Epoch 2/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.1846 - loss: 2.5457 - val_accuracy: 0.1493 - val_loss: 2.0751\n",
            "Epoch 3/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.2132 - loss: 2.3043 - val_accuracy: 0.1493 - val_loss: 2.0815\n",
            "Epoch 4/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - accuracy: 0.2986 - loss: 2.1674 - val_accuracy: 0.1493 - val_loss: 2.0936\n",
            "Epoch 5/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.3436 - loss: 1.9708 - val_accuracy: 0.1493 - val_loss: 2.1009\n",
            "Epoch 6/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.2971 - loss: 2.0536 - val_accuracy: 0.1493 - val_loss: 2.1101\n",
            "Epoch 7/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.3541 - loss: 1.8454 - val_accuracy: 0.1493 - val_loss: 2.1093\n",
            "Epoch 8/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.3715 - loss: 1.7708 - val_accuracy: 0.1493 - val_loss: 2.0907\n",
            "Epoch 9/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.3958 - loss: 1.7272 - val_accuracy: 0.1493 - val_loss: 2.0653\n",
            "Epoch 10/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.4197 - loss: 1.6072 - val_accuracy: 0.1493 - val_loss: 2.0328\n",
            "Epoch 11/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.4268 - loss: 1.5617 - val_accuracy: 0.1493 - val_loss: 1.9966\n",
            "Epoch 12/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.4140 - loss: 1.5781 - val_accuracy: 0.1597 - val_loss: 1.9594\n",
            "Epoch 13/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.4501 - loss: 1.5230 - val_accuracy: 0.1944 - val_loss: 1.8912\n",
            "Epoch 14/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.4256 - loss: 1.6372 - val_accuracy: 0.2292 - val_loss: 1.8441\n",
            "Epoch 15/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.4570 - loss: 1.4784 - val_accuracy: 0.3090 - val_loss: 1.7268\n",
            "Epoch 16/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.4896 - loss: 1.4426 - val_accuracy: 0.3750 - val_loss: 1.6479\n",
            "Epoch 17/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.4931 - loss: 1.3883 - val_accuracy: 0.4028 - val_loss: 1.6115\n",
            "Epoch 18/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.5113 - loss: 1.3179 - val_accuracy: 0.4167 - val_loss: 1.5444\n",
            "Epoch 19/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.5044 - loss: 1.3209 - val_accuracy: 0.4826 - val_loss: 1.4472\n",
            "Epoch 20/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.5431 - loss: 1.3569 - val_accuracy: 0.5417 - val_loss: 1.3473\n",
            "Epoch 21/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.5339 - loss: 1.2554 - val_accuracy: 0.5312 - val_loss: 1.3508\n",
            "Epoch 22/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.5581 - loss: 1.2160 - val_accuracy: 0.5382 - val_loss: 1.3030\n",
            "Epoch 23/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.6179 - loss: 1.0955 - val_accuracy: 0.5590 - val_loss: 1.2538\n",
            "Epoch 24/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.6052 - loss: 1.1364 - val_accuracy: 0.5417 - val_loss: 1.2482\n",
            "Epoch 25/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.5989 - loss: 1.1554 - val_accuracy: 0.5833 - val_loss: 1.1660\n",
            "Epoch 26/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.6283 - loss: 1.0411 - val_accuracy: 0.5833 - val_loss: 1.1583\n",
            "Epoch 27/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.6296 - loss: 1.0680 - val_accuracy: 0.5799 - val_loss: 1.1286\n",
            "Epoch 28/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.6459 - loss: 1.0504 - val_accuracy: 0.5903 - val_loss: 1.1055\n",
            "Epoch 29/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.6337 - loss: 1.0070 - val_accuracy: 0.6215 - val_loss: 1.0650\n",
            "Epoch 30/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.6571 - loss: 1.0162 - val_accuracy: 0.6424 - val_loss: 1.0581\n",
            "Epoch 31/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.6193 - loss: 1.0154 - val_accuracy: 0.6493 - val_loss: 1.0181\n",
            "Epoch 32/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.6685 - loss: 0.8979 - val_accuracy: 0.6389 - val_loss: 1.0253\n",
            "Epoch 33/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.6709 - loss: 0.9018 - val_accuracy: 0.6562 - val_loss: 0.9904\n",
            "Epoch 34/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.7057 - loss: 0.8682 - val_accuracy: 0.6042 - val_loss: 1.0900\n",
            "Epoch 35/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.6985 - loss: 0.8342 - val_accuracy: 0.6736 - val_loss: 0.9660\n",
            "Epoch 36/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.7047 - loss: 0.8358 - val_accuracy: 0.6285 - val_loss: 0.9914\n",
            "Epoch 37/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.7306 - loss: 0.8252 - val_accuracy: 0.6736 - val_loss: 0.8885\n",
            "Epoch 38/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.7021 - loss: 0.8254 - val_accuracy: 0.6806 - val_loss: 0.9036\n",
            "Epoch 39/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7203 - loss: 0.7972 - val_accuracy: 0.6736 - val_loss: 0.9339\n",
            "Epoch 40/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7319 - loss: 0.7833 - val_accuracy: 0.6667 - val_loss: 0.9667\n",
            "Epoch 41/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.7282 - loss: 0.7677 - val_accuracy: 0.6667 - val_loss: 0.9577\n",
            "Epoch 42/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.7474 - loss: 0.7627 - val_accuracy: 0.7014 - val_loss: 0.9025\n",
            "Epoch 43/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.7257 - loss: 0.7694 - val_accuracy: 0.6771 - val_loss: 0.9455\n",
            "Epoch 44/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.7760 - loss: 0.7082 - val_accuracy: 0.7153 - val_loss: 0.8887\n",
            "Epoch 45/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7681 - loss: 0.6840 - val_accuracy: 0.6979 - val_loss: 0.8951\n",
            "Epoch 46/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7635 - loss: 0.6867 - val_accuracy: 0.6667 - val_loss: 0.9245\n",
            "Epoch 47/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.7770 - loss: 0.6925 - val_accuracy: 0.7188 - val_loss: 0.8271\n",
            "Epoch 48/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.7870 - loss: 0.6293 - val_accuracy: 0.7188 - val_loss: 0.8277\n",
            "Epoch 49/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.7921 - loss: 0.6077 - val_accuracy: 0.7118 - val_loss: 0.8154\n",
            "Epoch 50/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.7772 - loss: 0.6413 - val_accuracy: 0.7083 - val_loss: 0.8417\n",
            "Epoch 51/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.7955 - loss: 0.5873 - val_accuracy: 0.7153 - val_loss: 0.8441\n",
            "Epoch 52/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.7927 - loss: 0.6277 - val_accuracy: 0.6806 - val_loss: 0.8832\n",
            "Epoch 53/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.8184 - loss: 0.5576 - val_accuracy: 0.6771 - val_loss: 0.8446\n",
            "Epoch 54/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.8408 - loss: 0.5287 - val_accuracy: 0.7083 - val_loss: 0.8137\n",
            "Epoch 55/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8224 - loss: 0.5590 - val_accuracy: 0.7396 - val_loss: 0.7983\n",
            "Epoch 56/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8390 - loss: 0.5130 - val_accuracy: 0.7222 - val_loss: 0.8099\n",
            "Epoch 57/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8283 - loss: 0.5352 - val_accuracy: 0.7361 - val_loss: 0.7569\n",
            "Epoch 58/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8531 - loss: 0.5014 - val_accuracy: 0.7535 - val_loss: 0.7559\n",
            "Epoch 59/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8322 - loss: 0.5187 - val_accuracy: 0.7431 - val_loss: 0.7722\n",
            "Epoch 60/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.8432 - loss: 0.5085 - val_accuracy: 0.7222 - val_loss: 0.7658\n",
            "Epoch 61/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8603 - loss: 0.4733 - val_accuracy: 0.7431 - val_loss: 0.7234\n",
            "Epoch 62/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 0.8559 - loss: 0.4594 - val_accuracy: 0.7569 - val_loss: 0.7160\n",
            "Epoch 63/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.8489 - loss: 0.4965 - val_accuracy: 0.7465 - val_loss: 0.7012\n",
            "Epoch 64/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.8533 - loss: 0.4785 - val_accuracy: 0.7465 - val_loss: 0.7176\n",
            "Epoch 65/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8699 - loss: 0.4362 - val_accuracy: 0.7431 - val_loss: 0.7376\n",
            "Epoch 66/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.8761 - loss: 0.4378 - val_accuracy: 0.7222 - val_loss: 0.7675\n",
            "Epoch 67/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.8643 - loss: 0.4344 - val_accuracy: 0.7326 - val_loss: 0.7481\n",
            "Epoch 68/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.8677 - loss: 0.4367 - val_accuracy: 0.7361 - val_loss: 0.7276\n",
            "Epoch 69/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.8866 - loss: 0.3820 - val_accuracy: 0.7326 - val_loss: 0.7392\n",
            "Epoch 70/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.8806 - loss: 0.4108 - val_accuracy: 0.7396 - val_loss: 0.7227\n",
            "Epoch 71/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.8793 - loss: 0.3813 - val_accuracy: 0.7535 - val_loss: 0.6939\n",
            "Epoch 72/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 179ms/step - accuracy: 0.8769 - loss: 0.3817 - val_accuracy: 0.7535 - val_loss: 0.7024\n",
            "Epoch 73/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.8851 - loss: 0.3730 - val_accuracy: 0.7535 - val_loss: 0.7035\n",
            "Epoch 74/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9075 - loss: 0.3311 - val_accuracy: 0.7500 - val_loss: 0.7311\n",
            "Epoch 75/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.8979 - loss: 0.3467 - val_accuracy: 0.7569 - val_loss: 0.6879\n",
            "Epoch 76/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.8985 - loss: 0.3720 - val_accuracy: 0.7465 - val_loss: 0.6749\n",
            "Epoch 77/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8979 - loss: 0.3359 - val_accuracy: 0.7569 - val_loss: 0.6916\n",
            "Epoch 78/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9093 - loss: 0.3278 - val_accuracy: 0.7639 - val_loss: 0.6573\n",
            "Epoch 79/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.8974 - loss: 0.3386 - val_accuracy: 0.7812 - val_loss: 0.6448\n",
            "Epoch 80/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.9093 - loss: 0.3189 - val_accuracy: 0.7604 - val_loss: 0.6486\n",
            "Epoch 81/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.9097 - loss: 0.2963 - val_accuracy: 0.7708 - val_loss: 0.6345\n",
            "Epoch 82/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.9010 - loss: 0.3092 - val_accuracy: 0.7986 - val_loss: 0.6134\n",
            "Epoch 83/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.9356 - loss: 0.2776 - val_accuracy: 0.8021 - val_loss: 0.6209\n",
            "Epoch 84/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.9135 - loss: 0.2994 - val_accuracy: 0.8125 - val_loss: 0.6272\n",
            "Epoch 85/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9262 - loss: 0.2738 - val_accuracy: 0.7917 - val_loss: 0.6182\n",
            "Epoch 86/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9159 - loss: 0.3095 - val_accuracy: 0.7882 - val_loss: 0.6209\n",
            "Epoch 87/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9245 - loss: 0.2694 - val_accuracy: 0.7847 - val_loss: 0.6526\n",
            "Epoch 88/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.9439 - loss: 0.2396 - val_accuracy: 0.7778 - val_loss: 0.6721\n",
            "Epoch 89/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9383 - loss: 0.2404 - val_accuracy: 0.7986 - val_loss: 0.6568\n",
            "Epoch 90/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9308 - loss: 0.2645 - val_accuracy: 0.7743 - val_loss: 0.6788\n",
            "Epoch 91/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9371 - loss: 0.2405 - val_accuracy: 0.7847 - val_loss: 0.6397\n",
            "Epoch 92/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.9317 - loss: 0.2566 - val_accuracy: 0.7951 - val_loss: 0.6152\n",
            "Epoch 93/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.9413 - loss: 0.2214 - val_accuracy: 0.8021 - val_loss: 0.6014\n",
            "Epoch 94/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9232 - loss: 0.2698 - val_accuracy: 0.7986 - val_loss: 0.6196\n",
            "Epoch 95/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9246 - loss: 0.2501 - val_accuracy: 0.8021 - val_loss: 0.6186\n",
            "Epoch 96/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9450 - loss: 0.2231 - val_accuracy: 0.8090 - val_loss: 0.6135\n",
            "Epoch 97/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9319 - loss: 0.2284 - val_accuracy: 0.8021 - val_loss: 0.6231\n",
            "Epoch 98/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9473 - loss: 0.2086 - val_accuracy: 0.8264 - val_loss: 0.5778\n",
            "Epoch 99/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.9422 - loss: 0.2206 - val_accuracy: 0.8299 - val_loss: 0.5772\n",
            "Epoch 100/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.9574 - loss: 0.1954 - val_accuracy: 0.8160 - val_loss: 0.5625\n"
          ]
        }
      ],
      "source": [
        "# Training the model with attention\n",
        "history_attention = model_with_attention.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BnL76UDCC53"
      },
      "source": [
        "### BLSTM with attenstion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-HmFLP1DsEH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hciEtskeD_Vv"
      },
      "outputs": [],
      "source": [
        "def build_bilstm_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add Bidirectional LSTM layers\n",
        "    model.add(Bidirectional(LSTM(512, return_sequences=True), input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Add Attention layer\n",
        "    model.add(Attention())\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output layer for classification\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "-M1QvbBZEFPE",
        "outputId": "f5c488b4-c1a6-470b-accd-2a445b7d3f1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,260,992</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,672</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_18               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_19               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m2,260,992\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_9 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m1,180,672\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_4 (\u001b[38;5;33mAttention\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │             \u001b[38;5;34m656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,448\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_18               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_19               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,469,080</span> (13.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,469,080\u001b[0m (13.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,466,264</span> (13.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,466,264\u001b[0m (13.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> (11.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,816\u001b[0m (11.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = build_bilstm_model(input_shape, num_classes)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qqLuQWpErqi",
        "outputId": "6d6704f9-25a4-4923-bfbc-ff9dcb5d2416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 369ms/step - accuracy: 0.1697 - loss: 2.7184 - val_accuracy: 0.1667 - val_loss: 2.0554\n",
            "Epoch 2/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 310ms/step - accuracy: 0.3151 - loss: 2.0877 - val_accuracy: 0.1632 - val_loss: 2.0534\n",
            "Epoch 3/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.3505 - loss: 1.8416 - val_accuracy: 0.1632 - val_loss: 2.0599\n",
            "Epoch 4/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 316ms/step - accuracy: 0.4029 - loss: 1.7149 - val_accuracy: 0.1632 - val_loss: 2.0680\n",
            "Epoch 5/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 316ms/step - accuracy: 0.4701 - loss: 1.5038 - val_accuracy: 0.1632 - val_loss: 2.0796\n",
            "Epoch 6/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 321ms/step - accuracy: 0.5089 - loss: 1.3661 - val_accuracy: 0.1632 - val_loss: 2.0842\n",
            "Epoch 7/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 317ms/step - accuracy: 0.5198 - loss: 1.3446 - val_accuracy: 0.1806 - val_loss: 2.0726\n",
            "Epoch 8/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.5811 - loss: 1.2232 - val_accuracy: 0.2118 - val_loss: 2.0497\n",
            "Epoch 9/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.5657 - loss: 1.1919 - val_accuracy: 0.3368 - val_loss: 2.0263\n",
            "Epoch 10/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.6316 - loss: 1.1201 - val_accuracy: 0.2917 - val_loss: 1.9868\n",
            "Epoch 11/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.6465 - loss: 0.9924 - val_accuracy: 0.3750 - val_loss: 1.9254\n",
            "Epoch 12/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 320ms/step - accuracy: 0.6885 - loss: 0.8951 - val_accuracy: 0.3750 - val_loss: 1.8641\n",
            "Epoch 13/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.6827 - loss: 0.9111 - val_accuracy: 0.4236 - val_loss: 1.7710\n",
            "Epoch 14/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 324ms/step - accuracy: 0.7274 - loss: 0.8359 - val_accuracy: 0.4375 - val_loss: 1.6670\n",
            "Epoch 15/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 319ms/step - accuracy: 0.7531 - loss: 0.7627 - val_accuracy: 0.4653 - val_loss: 1.5374\n",
            "Epoch 16/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 340ms/step - accuracy: 0.7662 - loss: 0.7278 - val_accuracy: 0.4896 - val_loss: 1.4288\n",
            "Epoch 17/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 319ms/step - accuracy: 0.7826 - loss: 0.6729 - val_accuracy: 0.5278 - val_loss: 1.3448\n",
            "Epoch 18/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.8013 - loss: 0.6437 - val_accuracy: 0.5694 - val_loss: 1.2048\n",
            "Epoch 19/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 321ms/step - accuracy: 0.8063 - loss: 0.5791 - val_accuracy: 0.5729 - val_loss: 1.1111\n",
            "Epoch 20/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.8125 - loss: 0.5688 - val_accuracy: 0.5938 - val_loss: 1.0667\n",
            "Epoch 21/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.8251 - loss: 0.5391 - val_accuracy: 0.6597 - val_loss: 0.9501\n",
            "Epoch 22/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.8575 - loss: 0.5113 - val_accuracy: 0.6840 - val_loss: 0.8362\n",
            "Epoch 23/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 316ms/step - accuracy: 0.8368 - loss: 0.4883 - val_accuracy: 0.7326 - val_loss: 0.7854\n",
            "Epoch 24/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.8578 - loss: 0.4625 - val_accuracy: 0.7292 - val_loss: 0.7625\n",
            "Epoch 25/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.8624 - loss: 0.4602 - val_accuracy: 0.7743 - val_loss: 0.6734\n",
            "Epoch 26/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.8765 - loss: 0.4126 - val_accuracy: 0.7674 - val_loss: 0.6554\n",
            "Epoch 27/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.8790 - loss: 0.4067 - val_accuracy: 0.7917 - val_loss: 0.6276\n",
            "Epoch 28/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9087 - loss: 0.3468 - val_accuracy: 0.8160 - val_loss: 0.5638\n",
            "Epoch 29/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 317ms/step - accuracy: 0.8847 - loss: 0.3579 - val_accuracy: 0.8299 - val_loss: 0.5891\n",
            "Epoch 30/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9047 - loss: 0.3506 - val_accuracy: 0.8056 - val_loss: 0.5631\n",
            "Epoch 31/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 317ms/step - accuracy: 0.9150 - loss: 0.3291 - val_accuracy: 0.7986 - val_loss: 0.5947\n",
            "Epoch 32/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 326ms/step - accuracy: 0.9120 - loss: 0.3344 - val_accuracy: 0.8194 - val_loss: 0.5651\n",
            "Epoch 33/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9385 - loss: 0.2885 - val_accuracy: 0.8056 - val_loss: 0.5841\n",
            "Epoch 34/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9519 - loss: 0.2626 - val_accuracy: 0.8264 - val_loss: 0.5389\n",
            "Epoch 35/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9432 - loss: 0.2546 - val_accuracy: 0.8333 - val_loss: 0.5473\n",
            "Epoch 36/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9458 - loss: 0.2545 - val_accuracy: 0.8472 - val_loss: 0.5023\n",
            "Epoch 37/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 324ms/step - accuracy: 0.9455 - loss: 0.2598 - val_accuracy: 0.8299 - val_loss: 0.5028\n",
            "Epoch 38/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9432 - loss: 0.2537 - val_accuracy: 0.8368 - val_loss: 0.4954\n",
            "Epoch 39/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9433 - loss: 0.2503 - val_accuracy: 0.8403 - val_loss: 0.5288\n",
            "Epoch 40/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9578 - loss: 0.2010 - val_accuracy: 0.8472 - val_loss: 0.4994\n",
            "Epoch 41/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9580 - loss: 0.2182 - val_accuracy: 0.8368 - val_loss: 0.4805\n",
            "Epoch 42/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.9523 - loss: 0.2082 - val_accuracy: 0.8507 - val_loss: 0.4685\n",
            "Epoch 43/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9624 - loss: 0.1898 - val_accuracy: 0.8507 - val_loss: 0.4739\n",
            "Epoch 44/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9703 - loss: 0.1767 - val_accuracy: 0.8368 - val_loss: 0.4865\n",
            "Epoch 45/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9673 - loss: 0.1798 - val_accuracy: 0.8438 - val_loss: 0.4662\n",
            "Epoch 46/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 323ms/step - accuracy: 0.9640 - loss: 0.1772 - val_accuracy: 0.8576 - val_loss: 0.4519\n",
            "Epoch 47/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 322ms/step - accuracy: 0.9744 - loss: 0.1650 - val_accuracy: 0.8472 - val_loss: 0.4720\n",
            "Epoch 48/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9758 - loss: 0.1582 - val_accuracy: 0.8472 - val_loss: 0.4785\n",
            "Epoch 49/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 317ms/step - accuracy: 0.9621 - loss: 0.1671 - val_accuracy: 0.8472 - val_loss: 0.4721\n",
            "Epoch 50/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 316ms/step - accuracy: 0.9651 - loss: 0.1611 - val_accuracy: 0.8646 - val_loss: 0.4505\n",
            "Epoch 51/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9676 - loss: 0.1470 - val_accuracy: 0.8438 - val_loss: 0.4598\n",
            "Epoch 52/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9726 - loss: 0.1594 - val_accuracy: 0.8646 - val_loss: 0.4384\n",
            "Epoch 53/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9783 - loss: 0.1392 - val_accuracy: 0.8785 - val_loss: 0.4387\n",
            "Epoch 54/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - accuracy: 0.9813 - loss: 0.1226 - val_accuracy: 0.8785 - val_loss: 0.4330\n",
            "Epoch 55/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9834 - loss: 0.1171 - val_accuracy: 0.8750 - val_loss: 0.4255\n",
            "Epoch 56/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9825 - loss: 0.1228 - val_accuracy: 0.8646 - val_loss: 0.4349\n",
            "Epoch 57/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9815 - loss: 0.1169 - val_accuracy: 0.8750 - val_loss: 0.4239\n",
            "Epoch 58/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 351ms/step - accuracy: 0.9810 - loss: 0.1218 - val_accuracy: 0.8646 - val_loss: 0.4097\n",
            "Epoch 59/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 318ms/step - accuracy: 0.9941 - loss: 0.0894 - val_accuracy: 0.8854 - val_loss: 0.3894\n",
            "Epoch 60/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 328ms/step - accuracy: 0.9759 - loss: 0.1189 - val_accuracy: 0.8785 - val_loss: 0.4161\n",
            "Epoch 61/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 316ms/step - accuracy: 0.9850 - loss: 0.0960 - val_accuracy: 0.8958 - val_loss: 0.4000\n",
            "Epoch 62/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9893 - loss: 0.0945 - val_accuracy: 0.8576 - val_loss: 0.4371\n",
            "Epoch 63/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9769 - loss: 0.1200 - val_accuracy: 0.8681 - val_loss: 0.4368\n",
            "Epoch 64/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9946 - loss: 0.0831 - val_accuracy: 0.8681 - val_loss: 0.4597\n",
            "Epoch 65/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 322ms/step - accuracy: 0.9874 - loss: 0.0948 - val_accuracy: 0.8681 - val_loss: 0.4295\n",
            "Epoch 66/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 324ms/step - accuracy: 0.9848 - loss: 0.0839 - val_accuracy: 0.8785 - val_loss: 0.4079\n",
            "Epoch 67/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9923 - loss: 0.0802 - val_accuracy: 0.8924 - val_loss: 0.4070\n",
            "Epoch 68/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9932 - loss: 0.0827 - val_accuracy: 0.8854 - val_loss: 0.3970\n",
            "Epoch 69/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9887 - loss: 0.0772 - val_accuracy: 0.8785 - val_loss: 0.4030\n",
            "Epoch 70/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 317ms/step - accuracy: 0.9863 - loss: 0.0902 - val_accuracy: 0.8681 - val_loss: 0.4177\n",
            "Epoch 71/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9876 - loss: 0.0865 - val_accuracy: 0.8993 - val_loss: 0.3942\n",
            "Epoch 72/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9893 - loss: 0.0827 - val_accuracy: 0.8889 - val_loss: 0.3837\n",
            "Epoch 73/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 323ms/step - accuracy: 0.9885 - loss: 0.0763 - val_accuracy: 0.8785 - val_loss: 0.4266\n",
            "Epoch 74/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 326ms/step - accuracy: 0.9929 - loss: 0.0770 - val_accuracy: 0.8924 - val_loss: 0.4058\n",
            "Epoch 75/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 316ms/step - accuracy: 0.9924 - loss: 0.0718 - val_accuracy: 0.8958 - val_loss: 0.3947\n",
            "Epoch 76/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 316ms/step - accuracy: 0.9968 - loss: 0.0539 - val_accuracy: 0.8958 - val_loss: 0.3900\n",
            "Epoch 77/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 323ms/step - accuracy: 0.9885 - loss: 0.0702 - val_accuracy: 0.8958 - val_loss: 0.4141\n",
            "Epoch 78/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9930 - loss: 0.0615 - val_accuracy: 0.8889 - val_loss: 0.4022\n",
            "Epoch 79/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9976 - loss: 0.0579 - val_accuracy: 0.8889 - val_loss: 0.4034\n",
            "Epoch 80/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9933 - loss: 0.0588 - val_accuracy: 0.9028 - val_loss: 0.3743\n",
            "Epoch 81/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 327ms/step - accuracy: 0.9948 - loss: 0.0627 - val_accuracy: 0.8854 - val_loss: 0.3986\n",
            "Epoch 82/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 319ms/step - accuracy: 0.9934 - loss: 0.0614 - val_accuracy: 0.8958 - val_loss: 0.3821\n",
            "Epoch 83/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 326ms/step - accuracy: 0.9944 - loss: 0.0555 - val_accuracy: 0.8958 - val_loss: 0.3897\n",
            "Epoch 84/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9969 - loss: 0.0552 - val_accuracy: 0.8854 - val_loss: 0.3980\n",
            "Epoch 85/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 316ms/step - accuracy: 0.9922 - loss: 0.0634 - val_accuracy: 0.8889 - val_loss: 0.4012\n",
            "Epoch 86/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 323ms/step - accuracy: 0.9952 - loss: 0.0447 - val_accuracy: 0.8819 - val_loss: 0.3999\n",
            "Epoch 87/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9927 - loss: 0.0609 - val_accuracy: 0.8819 - val_loss: 0.4105\n",
            "Epoch 88/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9995 - loss: 0.0415 - val_accuracy: 0.8889 - val_loss: 0.3939\n",
            "Epoch 89/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9966 - loss: 0.0433 - val_accuracy: 0.8854 - val_loss: 0.3794\n",
            "Epoch 90/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 325ms/step - accuracy: 0.9949 - loss: 0.0532 - val_accuracy: 0.8750 - val_loss: 0.4346\n",
            "Epoch 91/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 325ms/step - accuracy: 0.9932 - loss: 0.0494 - val_accuracy: 0.8854 - val_loss: 0.4184\n",
            "Epoch 92/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 332ms/step - accuracy: 0.9943 - loss: 0.0538 - val_accuracy: 0.9062 - val_loss: 0.3565\n",
            "Epoch 93/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 316ms/step - accuracy: 0.9970 - loss: 0.0475 - val_accuracy: 0.8750 - val_loss: 0.3696\n",
            "Epoch 94/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 318ms/step - accuracy: 0.9959 - loss: 0.0482 - val_accuracy: 0.9062 - val_loss: 0.3636\n",
            "Epoch 95/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9996 - loss: 0.0437 - val_accuracy: 0.9062 - val_loss: 0.3437\n",
            "Epoch 96/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 329ms/step - accuracy: 0.9975 - loss: 0.0411 - val_accuracy: 0.8924 - val_loss: 0.3738\n",
            "Epoch 97/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 0.0374 - val_accuracy: 0.8715 - val_loss: 0.3670\n",
            "Epoch 98/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.9969 - loss: 0.0410 - val_accuracy: 0.8819 - val_loss: 0.3544\n",
            "Epoch 99/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 316ms/step - accuracy: 0.9957 - loss: 0.0381 - val_accuracy: 0.8854 - val_loss: 0.3548\n",
            "Epoch 100/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9969 - loss: 0.0380 - val_accuracy: 0.8993 - val_loss: 0.3642\n"
          ]
        }
      ],
      "source": [
        "# Training the model with attention\n",
        "history_attention = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAsHFNgDJNuZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HuwerRVJTLh",
        "outputId": "f27450a8-4311-4e27-f26e-a93dbdc81f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd-LRHkzJa7d"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqpB4MIiJeF1"
      },
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ONxEKWnlJizH",
        "outputId": "ca1631ce-8c07-4dbd-f7e9-b0b7d8241780"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(num_classes))\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LuUgWBCIGfv"
      },
      "outputs": [],
      "source": [
        "#2nd bilstm attention model with rmsprop optimizer\n",
        "def build_bilstm_model1(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add Bidirectional LSTM layers\n",
        "    model.add(Bidirectional(LSTM(512, return_sequences=True), input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Add Attention layer\n",
        "    model.add(Attention())\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output layer for classification\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = RMSprop(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "-wzANZSxISp1",
        "outputId": "a488e5ce-7315-4d50-a964-c72dd16d46af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,260,992</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_20               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,672</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_21               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_22               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_23               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_10 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m2,260,992\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_20               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_11 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m1,180,672\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_21               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_5 (\u001b[38;5;33mAttention\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │             \u001b[38;5;34m656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m16,448\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_22               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_23               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,469,080</span> (13.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,469,080\u001b[0m (13.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,466,264</span> (13.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,466,264\u001b[0m (13.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> (11.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,816\u001b[0m (11.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = build_bilstm_model1(input_shape, num_classes)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE8pPTcgKAQ2",
        "outputId": "4d2f361a-faea-4247-f259-af2d2a044006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 353ms/step - accuracy: 0.1770 - loss: 2.7342 - val_accuracy: 0.1389 - val_loss: 2.0725\n",
            "Epoch 2/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 322ms/step - accuracy: 0.3018 - loss: 2.0820 - val_accuracy: 0.1389 - val_loss: 2.0721\n",
            "Epoch 3/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 319ms/step - accuracy: 0.4290 - loss: 1.6428 - val_accuracy: 0.1389 - val_loss: 2.0830\n",
            "Epoch 4/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.4101 - loss: 1.6167 - val_accuracy: 0.1389 - val_loss: 2.0901\n",
            "Epoch 5/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.5036 - loss: 1.4100 - val_accuracy: 0.1389 - val_loss: 2.0827\n",
            "Epoch 6/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.5325 - loss: 1.3136 - val_accuracy: 0.1389 - val_loss: 2.0804\n",
            "Epoch 7/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.5621 - loss: 1.1963 - val_accuracy: 0.1389 - val_loss: 2.0700\n",
            "Epoch 8/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.6121 - loss: 1.0845 - val_accuracy: 0.1458 - val_loss: 2.0343\n",
            "Epoch 9/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.6289 - loss: 1.0396 - val_accuracy: 0.1632 - val_loss: 1.9753\n",
            "Epoch 10/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 323ms/step - accuracy: 0.7146 - loss: 0.8805 - val_accuracy: 0.2153 - val_loss: 1.9327\n",
            "Epoch 11/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 348ms/step - accuracy: 0.7209 - loss: 0.8369 - val_accuracy: 0.2500 - val_loss: 1.7574\n",
            "Epoch 12/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.7403 - loss: 0.7815 - val_accuracy: 0.2743 - val_loss: 1.6907\n",
            "Epoch 13/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.7579 - loss: 0.7479 - val_accuracy: 0.3785 - val_loss: 1.5972\n",
            "Epoch 14/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.7657 - loss: 0.6745 - val_accuracy: 0.4722 - val_loss: 1.4471\n",
            "Epoch 15/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 323ms/step - accuracy: 0.8024 - loss: 0.6521 - val_accuracy: 0.5660 - val_loss: 1.3093\n",
            "Epoch 16/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.8453 - loss: 0.5702 - val_accuracy: 0.6875 - val_loss: 1.1187\n",
            "Epoch 17/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.8182 - loss: 0.5743 - val_accuracy: 0.6701 - val_loss: 1.0572\n",
            "Epoch 18/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.8420 - loss: 0.5513 - val_accuracy: 0.7014 - val_loss: 0.9685\n",
            "Epoch 19/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.8435 - loss: 0.5188 - val_accuracy: 0.7500 - val_loss: 0.8604\n",
            "Epoch 20/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.8708 - loss: 0.4748 - val_accuracy: 0.7708 - val_loss: 0.7720\n",
            "Epoch 21/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.8947 - loss: 0.4125 - val_accuracy: 0.7639 - val_loss: 0.7792\n",
            "Epoch 22/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.8660 - loss: 0.4458 - val_accuracy: 0.8160 - val_loss: 0.6630\n",
            "Epoch 23/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 323ms/step - accuracy: 0.8791 - loss: 0.4131 - val_accuracy: 0.7778 - val_loss: 0.6450\n",
            "Epoch 24/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.8978 - loss: 0.3712 - val_accuracy: 0.8438 - val_loss: 0.5712\n",
            "Epoch 25/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9124 - loss: 0.3577 - val_accuracy: 0.8368 - val_loss: 0.5436\n",
            "Epoch 26/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 322ms/step - accuracy: 0.9147 - loss: 0.3226 - val_accuracy: 0.8333 - val_loss: 0.5352\n",
            "Epoch 27/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9195 - loss: 0.3169 - val_accuracy: 0.8229 - val_loss: 0.5277\n",
            "Epoch 28/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9258 - loss: 0.2939 - val_accuracy: 0.8438 - val_loss: 0.4914\n",
            "Epoch 29/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9462 - loss: 0.2738 - val_accuracy: 0.8299 - val_loss: 0.4945\n",
            "Epoch 30/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 322ms/step - accuracy: 0.9340 - loss: 0.2815 - val_accuracy: 0.8472 - val_loss: 0.4935\n",
            "Epoch 31/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9539 - loss: 0.2555 - val_accuracy: 0.8403 - val_loss: 0.4894\n",
            "Epoch 32/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - accuracy: 0.9511 - loss: 0.2334 - val_accuracy: 0.8299 - val_loss: 0.4602\n",
            "Epoch 33/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9559 - loss: 0.2174 - val_accuracy: 0.8403 - val_loss: 0.4693\n",
            "Epoch 34/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9533 - loss: 0.2121 - val_accuracy: 0.8090 - val_loss: 0.5342\n",
            "Epoch 35/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9625 - loss: 0.2002 - val_accuracy: 0.8438 - val_loss: 0.4799\n",
            "Epoch 36/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9731 - loss: 0.1611 - val_accuracy: 0.8299 - val_loss: 0.4903\n",
            "Epoch 37/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9622 - loss: 0.1843 - val_accuracy: 0.8438 - val_loss: 0.4733\n",
            "Epoch 38/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9796 - loss: 0.1509 - val_accuracy: 0.8472 - val_loss: 0.5278\n",
            "Epoch 39/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9751 - loss: 0.1583 - val_accuracy: 0.8438 - val_loss: 0.4414\n",
            "Epoch 40/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9690 - loss: 0.1593 - val_accuracy: 0.8611 - val_loss: 0.4434\n",
            "Epoch 41/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9768 - loss: 0.1385 - val_accuracy: 0.8264 - val_loss: 0.4728\n",
            "Epoch 42/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9692 - loss: 0.1596 - val_accuracy: 0.8368 - val_loss: 0.4765\n",
            "Epoch 43/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9794 - loss: 0.1450 - val_accuracy: 0.8611 - val_loss: 0.4525\n",
            "Epoch 44/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 323ms/step - accuracy: 0.9753 - loss: 0.1481 - val_accuracy: 0.8403 - val_loss: 0.4546\n",
            "Epoch 45/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 321ms/step - accuracy: 0.9795 - loss: 0.1241 - val_accuracy: 0.8542 - val_loss: 0.4541\n",
            "Epoch 46/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9863 - loss: 0.1152 - val_accuracy: 0.8611 - val_loss: 0.4112\n",
            "Epoch 47/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9851 - loss: 0.1125 - val_accuracy: 0.8333 - val_loss: 0.4763\n",
            "Epoch 48/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9883 - loss: 0.0958 - val_accuracy: 0.8681 - val_loss: 0.4212\n",
            "Epoch 49/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9930 - loss: 0.0796 - val_accuracy: 0.8438 - val_loss: 0.4374\n",
            "Epoch 50/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.9870 - loss: 0.0951 - val_accuracy: 0.8368 - val_loss: 0.4440\n",
            "Epoch 51/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9865 - loss: 0.0869 - val_accuracy: 0.8299 - val_loss: 0.4792\n",
            "Epoch 52/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9888 - loss: 0.0847 - val_accuracy: 0.8611 - val_loss: 0.4324\n",
            "Epoch 53/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9840 - loss: 0.0894 - val_accuracy: 0.8542 - val_loss: 0.4623\n",
            "Epoch 54/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.9915 - loss: 0.0682 - val_accuracy: 0.8507 - val_loss: 0.4400\n",
            "Epoch 55/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9907 - loss: 0.0714 - val_accuracy: 0.8507 - val_loss: 0.4210\n",
            "Epoch 56/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9911 - loss: 0.0747 - val_accuracy: 0.8611 - val_loss: 0.4133\n",
            "Epoch 57/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9923 - loss: 0.0698 - val_accuracy: 0.8611 - val_loss: 0.4409\n",
            "Epoch 58/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 322ms/step - accuracy: 0.9947 - loss: 0.0653 - val_accuracy: 0.8542 - val_loss: 0.4501\n",
            "Epoch 59/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.9910 - loss: 0.0715 - val_accuracy: 0.8472 - val_loss: 0.4675\n",
            "Epoch 60/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9913 - loss: 0.0650 - val_accuracy: 0.8507 - val_loss: 0.4196\n",
            "Epoch 61/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 321ms/step - accuracy: 0.9906 - loss: 0.0649 - val_accuracy: 0.8507 - val_loss: 0.4442\n",
            "Epoch 62/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9948 - loss: 0.0559 - val_accuracy: 0.8646 - val_loss: 0.4449\n",
            "Epoch 63/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9879 - loss: 0.0629 - val_accuracy: 0.8264 - val_loss: 0.5008\n",
            "Epoch 64/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9983 - loss: 0.0457 - val_accuracy: 0.8403 - val_loss: 0.4976\n",
            "Epoch 65/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9938 - loss: 0.0528 - val_accuracy: 0.8611 - val_loss: 0.4399\n",
            "Epoch 66/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9987 - loss: 0.0464 - val_accuracy: 0.8472 - val_loss: 0.4364\n",
            "Epoch 67/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.9979 - loss: 0.0442 - val_accuracy: 0.8507 - val_loss: 0.4858\n",
            "Epoch 68/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9851 - loss: 0.0598 - val_accuracy: 0.8472 - val_loss: 0.4423\n",
            "Epoch 69/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.9931 - loss: 0.0482 - val_accuracy: 0.8854 - val_loss: 0.4029\n",
            "Epoch 70/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9982 - loss: 0.0412 - val_accuracy: 0.8819 - val_loss: 0.4232\n",
            "Epoch 71/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9998 - loss: 0.0324 - val_accuracy: 0.8472 - val_loss: 0.4848\n",
            "Epoch 72/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9971 - loss: 0.0360 - val_accuracy: 0.8681 - val_loss: 0.4241\n",
            "Epoch 73/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9972 - loss: 0.0422 - val_accuracy: 0.8611 - val_loss: 0.4371\n",
            "Epoch 74/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9984 - loss: 0.0384 - val_accuracy: 0.8819 - val_loss: 0.3895\n",
            "Epoch 75/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9997 - loss: 0.0299 - val_accuracy: 0.8750 - val_loss: 0.3902\n",
            "Epoch 76/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9958 - loss: 0.0296 - val_accuracy: 0.8785 - val_loss: 0.4263\n",
            "Epoch 77/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9942 - loss: 0.0342 - val_accuracy: 0.8681 - val_loss: 0.4334\n",
            "Epoch 78/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9971 - loss: 0.0312 - val_accuracy: 0.8715 - val_loss: 0.4283\n",
            "Epoch 79/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9963 - loss: 0.0399 - val_accuracy: 0.8854 - val_loss: 0.3717\n",
            "Epoch 80/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9990 - loss: 0.0285 - val_accuracy: 0.8785 - val_loss: 0.3569\n",
            "Epoch 81/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - accuracy: 0.9994 - loss: 0.0322 - val_accuracy: 0.8646 - val_loss: 0.3958\n",
            "Epoch 82/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.9983 - loss: 0.0294 - val_accuracy: 0.8611 - val_loss: 0.4406\n",
            "Epoch 83/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9989 - loss: 0.0236 - val_accuracy: 0.8889 - val_loss: 0.3770\n",
            "Epoch 84/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.9960 - loss: 0.0310 - val_accuracy: 0.8750 - val_loss: 0.3826\n",
            "Epoch 85/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.9996 - loss: 0.0256 - val_accuracy: 0.8854 - val_loss: 0.3438\n",
            "Epoch 86/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9999 - loss: 0.0191 - val_accuracy: 0.8715 - val_loss: 0.3700\n",
            "Epoch 87/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.9952 - loss: 0.0285 - val_accuracy: 0.8854 - val_loss: 0.3550\n",
            "Epoch 88/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.9952 - loss: 0.0292 - val_accuracy: 0.8889 - val_loss: 0.3830\n",
            "Epoch 89/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 324ms/step - accuracy: 0.9988 - loss: 0.0200 - val_accuracy: 0.8924 - val_loss: 0.3598\n",
            "Epoch 90/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9977 - loss: 0.0254 - val_accuracy: 0.8819 - val_loss: 0.3360\n",
            "Epoch 91/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9986 - loss: 0.0223 - val_accuracy: 0.8993 - val_loss: 0.3215\n",
            "Epoch 92/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.8993 - val_loss: 0.3384\n",
            "Epoch 93/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9964 - loss: 0.0271 - val_accuracy: 0.8715 - val_loss: 0.4146\n",
            "Epoch 94/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - accuracy: 0.9986 - loss: 0.0219 - val_accuracy: 0.8889 - val_loss: 0.3885\n",
            "Epoch 95/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9993 - loss: 0.0152 - val_accuracy: 0.8646 - val_loss: 0.4118\n",
            "Epoch 96/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.9994 - loss: 0.0157 - val_accuracy: 0.8750 - val_loss: 0.3965\n",
            "Epoch 97/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 0.0168 - val_accuracy: 0.8681 - val_loss: 0.4104\n",
            "Epoch 98/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.9990 - loss: 0.0154 - val_accuracy: 0.8715 - val_loss: 0.4145\n",
            "Epoch 99/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 315ms/step - accuracy: 0.9996 - loss: 0.0157 - val_accuracy: 0.8854 - val_loss: 0.3698\n",
            "Epoch 100/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 313ms/step - accuracy: 0.9992 - loss: 0.0129 - val_accuracy: 0.8819 - val_loss: 0.3673\n"
          ]
        }
      ],
      "source": [
        "# Training the model with attention\n",
        "history_attention = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI0Z3wRPN1TX"
      },
      "outputs": [],
      "source": [
        "history=history_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "5WrFJCwqNv4u",
        "outputId": "f4c836c0-6ce6-42bc-fae1-177863229ac4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(6, 3))\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# Show plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "roKtt7ioN_jD",
        "outputId": "04e24802-3d50-4437-d3ae-e1c5012d4020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "# Display confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(num_classes))\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGmuopYECV66"
      },
      "source": [
        "### 2DCNN+ LSTM with attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4wbOK0yFWgj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNqi1suUCH4d"
      },
      "outputs": [],
      "source": [
        "def build_cnn_lstm_attention_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Reshape input to add a channel dimension for Conv2D\n",
        "    model.add(Reshape((input_shape[0], input_shape[1], 1), input_shape=input_shape))  # Adding a channel dimension\n",
        "\n",
        "    # Add 2D CNN layers for feature extraction\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Flatten to feed into LSTM\n",
        "    model.add(Reshape((-1, 64)))  # Adjust this based on the CNN output size\n",
        "\n",
        "    # LSTM layer\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Add Attention\n",
        "    model.add(Attention())\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "ptNkJsT5CH2I",
        "outputId": "9e338936-05bd-4d0f-d14e-b299a834ca17"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">398</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_24               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_25               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_26               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">912</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_27               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_28               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m398\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_24               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m197\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_25               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m98,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_26               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_6 (\u001b[38;5;33mAttention\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m912\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_27               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_28               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132,888</span> (519.09 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m132,888\u001b[0m (519.09 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132,184</span> (516.34 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m132,184\u001b[0m (516.34 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = build_cnn_lstm_attention_model(input_shape, num_classes)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmBehNS5OkvS",
        "outputId": "034410f5-5cd6-4c5e-f9bf-312881a4abce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.1263 - loss: 2.9612 - val_accuracy: 0.1632 - val_loss: 2.0726\n",
            "Epoch 2/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.1269 - loss: 2.6608 - val_accuracy: 0.1632 - val_loss: 2.0720\n",
            "Epoch 3/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.1877 - loss: 2.4587 - val_accuracy: 0.1632 - val_loss: 2.0749\n",
            "Epoch 4/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.1976 - loss: 2.4465 - val_accuracy: 0.1632 - val_loss: 2.0794\n",
            "Epoch 5/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.1947 - loss: 2.4107 - val_accuracy: 0.1632 - val_loss: 2.0848\n",
            "Epoch 6/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.2211 - loss: 2.3951 - val_accuracy: 0.1632 - val_loss: 2.0911\n",
            "Epoch 7/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.2458 - loss: 2.1986 - val_accuracy: 0.1632 - val_loss: 2.0997\n",
            "Epoch 8/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.2345 - loss: 2.3016 - val_accuracy: 0.1632 - val_loss: 2.1088\n",
            "Epoch 9/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.2587 - loss: 2.1466 - val_accuracy: 0.1632 - val_loss: 2.1193\n",
            "Epoch 10/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.2980 - loss: 2.0797 - val_accuracy: 0.1632 - val_loss: 2.1339\n",
            "Epoch 11/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.2781 - loss: 2.1584 - val_accuracy: 0.1632 - val_loss: 2.1688\n",
            "Epoch 12/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.3023 - loss: 2.0999 - val_accuracy: 0.1632 - val_loss: 2.2255\n",
            "Epoch 13/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.2951 - loss: 2.1151 - val_accuracy: 0.1632 - val_loss: 2.2332\n",
            "Epoch 14/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.2799 - loss: 2.0058 - val_accuracy: 0.1806 - val_loss: 2.2493\n",
            "Epoch 15/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.3031 - loss: 2.0416 - val_accuracy: 0.2049 - val_loss: 2.2131\n",
            "Epoch 16/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.2971 - loss: 1.9917 - val_accuracy: 0.1910 - val_loss: 2.2488\n",
            "Epoch 17/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.3144 - loss: 1.9456 - val_accuracy: 0.1979 - val_loss: 2.3244\n",
            "Epoch 18/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.3354 - loss: 1.9067 - val_accuracy: 0.2014 - val_loss: 2.2854\n",
            "Epoch 19/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.3134 - loss: 1.9090 - val_accuracy: 0.1944 - val_loss: 2.2879\n",
            "Epoch 20/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.3711 - loss: 1.7676 - val_accuracy: 0.2049 - val_loss: 2.1703\n",
            "Epoch 21/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.3363 - loss: 1.8704 - val_accuracy: 0.2396 - val_loss: 2.0861\n",
            "Epoch 22/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.3619 - loss: 1.8032 - val_accuracy: 0.2639 - val_loss: 2.0591\n",
            "Epoch 23/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.3605 - loss: 1.8364 - val_accuracy: 0.3229 - val_loss: 1.8979\n",
            "Epoch 24/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.3334 - loss: 1.8675 - val_accuracy: 0.2917 - val_loss: 1.9828\n",
            "Epoch 25/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.3668 - loss: 1.8350 - val_accuracy: 0.3194 - val_loss: 1.8554\n",
            "Epoch 26/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.3761 - loss: 1.7435 - val_accuracy: 0.3368 - val_loss: 1.7662\n",
            "Epoch 27/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.3842 - loss: 1.7109 - val_accuracy: 0.3333 - val_loss: 1.7358\n",
            "Epoch 28/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.4072 - loss: 1.6603 - val_accuracy: 0.3090 - val_loss: 1.8200\n",
            "Epoch 29/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.4129 - loss: 1.7213 - val_accuracy: 0.3715 - val_loss: 1.6969\n",
            "Epoch 30/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.3784 - loss: 1.6945 - val_accuracy: 0.3403 - val_loss: 1.9091\n",
            "Epoch 31/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.4043 - loss: 1.7331 - val_accuracy: 0.3958 - val_loss: 1.6346\n",
            "Epoch 32/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.4011 - loss: 1.6555 - val_accuracy: 0.3333 - val_loss: 1.7342\n",
            "Epoch 33/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.4174 - loss: 1.6314 - val_accuracy: 0.3403 - val_loss: 1.8269\n",
            "Epoch 34/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.4445 - loss: 1.5815 - val_accuracy: 0.4167 - val_loss: 1.5880\n",
            "Epoch 35/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.4412 - loss: 1.6056 - val_accuracy: 0.4549 - val_loss: 1.5498\n",
            "Epoch 36/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.4432 - loss: 1.5888 - val_accuracy: 0.3785 - val_loss: 1.7230\n",
            "Epoch 37/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.4197 - loss: 1.6306 - val_accuracy: 0.4271 - val_loss: 1.5720\n",
            "Epoch 38/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.4704 - loss: 1.5421 - val_accuracy: 0.4826 - val_loss: 1.4909\n",
            "Epoch 39/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.4092 - loss: 1.5825 - val_accuracy: 0.4028 - val_loss: 1.7342\n",
            "Epoch 40/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.4385 - loss: 1.5378 - val_accuracy: 0.4097 - val_loss: 1.6041\n",
            "Epoch 41/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.4700 - loss: 1.5140 - val_accuracy: 0.2882 - val_loss: 2.5429\n",
            "Epoch 42/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.4633 - loss: 1.5007 - val_accuracy: 0.2986 - val_loss: 2.4784\n",
            "Epoch 43/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.4908 - loss: 1.5208 - val_accuracy: 0.3333 - val_loss: 2.1909\n",
            "Epoch 44/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.4472 - loss: 1.4996 - val_accuracy: 0.4931 - val_loss: 1.5366\n",
            "Epoch 45/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.4687 - loss: 1.4368 - val_accuracy: 0.4444 - val_loss: 1.7390\n",
            "Epoch 46/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.4798 - loss: 1.4564 - val_accuracy: 0.4236 - val_loss: 1.6345\n",
            "Epoch 47/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.4663 - loss: 1.5140 - val_accuracy: 0.4965 - val_loss: 1.4575\n",
            "Epoch 48/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.5131 - loss: 1.3846 - val_accuracy: 0.5139 - val_loss: 1.5095\n",
            "Epoch 49/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.4756 - loss: 1.4469 - val_accuracy: 0.4722 - val_loss: 1.5482\n",
            "Epoch 50/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.4791 - loss: 1.4807 - val_accuracy: 0.3958 - val_loss: 1.6923\n",
            "Epoch 51/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.4772 - loss: 1.4308 - val_accuracy: 0.5104 - val_loss: 1.5059\n",
            "Epoch 52/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5026 - loss: 1.3976 - val_accuracy: 0.4583 - val_loss: 1.5900\n",
            "Epoch 53/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.5043 - loss: 1.3928 - val_accuracy: 0.4896 - val_loss: 1.4516\n",
            "Epoch 54/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.5034 - loss: 1.3547 - val_accuracy: 0.4618 - val_loss: 1.4129\n",
            "Epoch 55/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.5269 - loss: 1.3454 - val_accuracy: 0.4722 - val_loss: 1.5099\n",
            "Epoch 56/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5393 - loss: 1.3458 - val_accuracy: 0.4896 - val_loss: 1.4750\n",
            "Epoch 57/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.5199 - loss: 1.3046 - val_accuracy: 0.4271 - val_loss: 1.7386\n",
            "Epoch 58/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5663 - loss: 1.2289 - val_accuracy: 0.4722 - val_loss: 1.4958\n",
            "Epoch 59/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.5113 - loss: 1.3141 - val_accuracy: 0.4479 - val_loss: 1.6827\n",
            "Epoch 60/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.5262 - loss: 1.3088 - val_accuracy: 0.4722 - val_loss: 1.5206\n",
            "Epoch 61/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.5410 - loss: 1.2879 - val_accuracy: 0.3681 - val_loss: 2.0000\n",
            "Epoch 62/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5241 - loss: 1.3517 - val_accuracy: 0.4306 - val_loss: 1.7011\n",
            "Epoch 63/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.5514 - loss: 1.2759 - val_accuracy: 0.5347 - val_loss: 1.4068\n",
            "Epoch 64/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.5409 - loss: 1.2940 - val_accuracy: 0.4931 - val_loss: 1.4408\n",
            "Epoch 65/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.5419 - loss: 1.2723 - val_accuracy: 0.4618 - val_loss: 1.5199\n",
            "Epoch 66/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.5811 - loss: 1.2269 - val_accuracy: 0.4965 - val_loss: 1.3991\n",
            "Epoch 67/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.5504 - loss: 1.2422 - val_accuracy: 0.5000 - val_loss: 1.4055\n",
            "Epoch 68/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.5619 - loss: 1.2624 - val_accuracy: 0.4410 - val_loss: 1.4609\n",
            "Epoch 69/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.5747 - loss: 1.2188 - val_accuracy: 0.4410 - val_loss: 1.6076\n",
            "Epoch 70/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.5665 - loss: 1.2353 - val_accuracy: 0.5069 - val_loss: 1.4389\n",
            "Epoch 71/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5707 - loss: 1.2091 - val_accuracy: 0.4653 - val_loss: 1.5525\n",
            "Epoch 72/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.5774 - loss: 1.1673 - val_accuracy: 0.5174 - val_loss: 1.3848\n",
            "Epoch 73/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.5509 - loss: 1.1619 - val_accuracy: 0.4688 - val_loss: 1.4785\n",
            "Epoch 74/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - accuracy: 0.5745 - loss: 1.1267 - val_accuracy: 0.4618 - val_loss: 1.5186\n",
            "Epoch 75/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5487 - loss: 1.2329 - val_accuracy: 0.4549 - val_loss: 1.5417\n",
            "Epoch 76/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.6181 - loss: 1.0721 - val_accuracy: 0.4965 - val_loss: 1.3970\n",
            "Epoch 77/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5769 - loss: 1.1749 - val_accuracy: 0.5451 - val_loss: 1.3196\n",
            "Epoch 78/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5683 - loss: 1.1570 - val_accuracy: 0.4792 - val_loss: 1.6749\n",
            "Epoch 79/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5911 - loss: 1.1047 - val_accuracy: 0.4340 - val_loss: 1.7746\n",
            "Epoch 80/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6089 - loss: 1.1184 - val_accuracy: 0.4201 - val_loss: 1.9310\n",
            "Epoch 81/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.5750 - loss: 1.1311 - val_accuracy: 0.4444 - val_loss: 1.9504\n",
            "Epoch 82/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6200 - loss: 1.1195 - val_accuracy: 0.4375 - val_loss: 2.1202\n",
            "Epoch 83/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.6200 - loss: 1.0591 - val_accuracy: 0.5417 - val_loss: 1.3881\n",
            "Epoch 84/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.5889 - loss: 1.1312 - val_accuracy: 0.4931 - val_loss: 1.4731\n",
            "Epoch 85/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6002 - loss: 1.1244 - val_accuracy: 0.4583 - val_loss: 1.7653\n",
            "Epoch 86/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.5986 - loss: 1.0992 - val_accuracy: 0.4062 - val_loss: 1.9687\n",
            "Epoch 87/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.5974 - loss: 1.0951 - val_accuracy: 0.4653 - val_loss: 1.8316\n",
            "Epoch 88/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.6292 - loss: 1.0343 - val_accuracy: 0.5521 - val_loss: 1.3727\n",
            "Epoch 89/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.6273 - loss: 1.0544 - val_accuracy: 0.5347 - val_loss: 1.3813\n",
            "Epoch 90/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.6198 - loss: 1.0599 - val_accuracy: 0.4792 - val_loss: 1.6215\n",
            "Epoch 91/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.5976 - loss: 1.0844 - val_accuracy: 0.5312 - val_loss: 1.5065\n",
            "Epoch 92/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.6294 - loss: 1.0332 - val_accuracy: 0.4931 - val_loss: 1.5316\n",
            "Epoch 93/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.6348 - loss: 1.0517 - val_accuracy: 0.5521 - val_loss: 1.2589\n",
            "Epoch 94/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.6044 - loss: 1.0158 - val_accuracy: 0.5938 - val_loss: 1.3335\n",
            "Epoch 95/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.6289 - loss: 1.0392 - val_accuracy: 0.4167 - val_loss: 2.0038\n",
            "Epoch 96/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.6386 - loss: 1.0427 - val_accuracy: 0.5347 - val_loss: 1.4315\n",
            "Epoch 97/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6397 - loss: 1.0155 - val_accuracy: 0.5660 - val_loss: 1.4281\n",
            "Epoch 98/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.6416 - loss: 1.0110 - val_accuracy: 0.4861 - val_loss: 1.6518\n",
            "Epoch 99/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.6532 - loss: 0.9823 - val_accuracy: 0.5382 - val_loss: 1.4417\n",
            "Epoch 100/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.6391 - loss: 0.9859 - val_accuracy: 0.4514 - val_loss: 1.9091\n"
          ]
        }
      ],
      "source": [
        "# Training the model with attention\n",
        "history_attention = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-XjgJltPg38"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}